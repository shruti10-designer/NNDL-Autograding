{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3As9Fi7DsDZ"
      },
      "outputs": [],
      "source": [
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "LYVDbgTrDtOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "ZNH2IwZQDvuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code = pd.read_excel(r\"/content/totalmerged.xlsx\")\n",
        "code"
      ],
      "metadata": {
        "id": "n8UNmfZ9DzcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge columns\n",
        "code['merged'] = code['Question'] + ' ' + code['Code_with_Error']\n",
        "code"
      ],
      "metadata": {
        "id": "kUQolp6dD1AX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with empty strings\n",
        "code['merged'] = code['merged'].fillna('')"
      ],
      "metadata": {
        "id": "ycpgNKmvEXRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "id": "rxpX3y2mEYuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and convert the textual data to vectors\n",
        "X_text = code[\"merged\"].values\n",
        "y = code[\"Total_Marks\"].values"
      ],
      "metadata": {
        "id": "qXLh9jPpEaRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_vectors = []\n",
        "for text in X_text:\n",
        "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='tf', max_length=512, truncation=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    output = roberta_model(input_ids, attention_mask=attention_mask)[0][:, 0, :]\n",
        "    X_vectors.append(output.numpy())"
      ],
      "metadata": {
        "id": "oML493H7Eb-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_vectors = np.array(X_vectors)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "ohYjkHL-EdgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_vectors"
      ],
      "metadata": {
        "id": "-RYrLovSEggR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.25, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "1_arIQu8EiAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the BiLSTM model\n",
        "model = Sequential()\n",
        "model.add(Bidirectional(LSTM(units=64), input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "jWq1-uDiE9Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "q3CIN0e3E-zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=32, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "FO8vSykoFBYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "kFSpGEW1FDdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
        "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "1LBgIoQRFFmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metrics\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Test RMSE:\", test_rmse)\n",
        "print() \n",
        "print(\"Train MAE:\", train_mae)\n",
        "print(\"Test MAE:\", test_mae)\n",
        "print() \n",
        "print(\"Train MAPE:\", train_mape)\n",
        "print(\"Test MAPE:\", test_mape)\n",
        "print() \n",
        "print(\"Train R^2:\", train_r2)\n",
        "print(\"Test R^2:\", test_r2)"
      ],
      "metadata": {
        "id": "hs8KKPiUFLVp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}