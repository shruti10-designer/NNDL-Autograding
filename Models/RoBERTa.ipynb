{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4V0U2vl2Fhx",
        "outputId": "b8b4e7e0-30ea-401f-9f00-fe907f790780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sHEOObb5FgS",
        "outputId": "b41cb286-6373-42ea-a121-09b7ef9adfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
        "from transformers import RobertaTokenizer, TFRobertaModel\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "GXy9mrZJ2neO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code = pd.read_excel(r\"/content/totalmerged.xlsx\")\n",
        "code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "cfvtxjJA2rxi",
        "outputId": "3b06e215-2230-4a5d-a01c-e13b01df147d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Question  \\\n",
              "0                        Print the factors of a number   \n",
              "1                        Print the factors of a number   \n",
              "2                        Print the factors of a number   \n",
              "3                        Print the factors of a number   \n",
              "4                        Print the factors of a number   \n",
              "..                                                 ...   \n",
              "995  Print maximum Occurring Character in a String ...   \n",
              "996  Print maximum Occurring Character in a String ...   \n",
              "997  Print maximum Occurring Character in a String ...   \n",
              "998  Print maximum Occurring Character in a String ...   \n",
              "999  Print maximum Occurring Character in a String ...   \n",
              "\n",
              "                                          Correct_Code  \\\n",
              "0    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "1    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "2    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "3    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "4    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "..                                                 ...   \n",
              "995  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "996  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "997  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "998  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "999  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "\n",
              "                                       Code_with_Error  Total_Marks  \n",
              "0    #include <stdio.h>\\nvoid printFactors(int numb...          7.0  \n",
              "1    #include <stdio.h>\\nvoid printFactors(int numb...          8.0  \n",
              "2    #include <stdio.h>\\nvoid printFactors(int numb...          5.0  \n",
              "3    #include <stdio.h>\\n\\nvoid printFactors(int nu...          7.0  \n",
              "4    #include <stdio.h>\\n\\nvoid printFactors(int nu...          5.0  \n",
              "..                                                 ...          ...  \n",
              "995  #include <stdio.h> \\n\\n#define MAX_SIZE 100 \\n...          7.0  \n",
              "996  #include <stdio.h> \\n\\nchar getMaxOccurringCha...          6.0  \n",
              "997  #include <stdio.h> \\n\\nchar getMaxOccurringCha...          6.0  \n",
              "998  #include <stdio.h> \\n\\n#define ASCII_SIZE 128 ...          5.0  \n",
              "999  #include <stdio.h> \\n\\n#define ASCII_SIZE 128 ...          6.0  \n",
              "\n",
              "[1000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3349d78-ee50-495e-8084-2f49a79ca3f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Correct_Code</th>\n",
              "      <th>Code_with_Error</th>\n",
              "      <th>Total_Marks</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\n#define MAX_SIZE 100 \\n...</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\nchar getMaxOccurringCha...</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\nchar getMaxOccurringCha...</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\n#define ASCII_SIZE 128 ...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\n#define ASCII_SIZE 128 ...</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3349d78-ee50-495e-8084-2f49a79ca3f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b3349d78-ee50-495e-8084-2f49a79ca3f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b3349d78-ee50-495e-8084-2f49a79ca3f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge columns\n",
        "code['merged'] = code['Question'] + ' ' + code['Code_with_Error']\n",
        "code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "QoH1IZLy2sH8",
        "outputId": "2a0ff57f-a8ac-4422-ece9-0c4fa67c2f93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Question  \\\n",
              "0                        Print the factors of a number   \n",
              "1                        Print the factors of a number   \n",
              "2                        Print the factors of a number   \n",
              "3                        Print the factors of a number   \n",
              "4                        Print the factors of a number   \n",
              "..                                                 ...   \n",
              "995  Print maximum Occurring Character in a String ...   \n",
              "996  Print maximum Occurring Character in a String ...   \n",
              "997  Print maximum Occurring Character in a String ...   \n",
              "998  Print maximum Occurring Character in a String ...   \n",
              "999  Print maximum Occurring Character in a String ...   \n",
              "\n",
              "                                          Correct_Code  \\\n",
              "0    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "1    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "2    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "3    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "4    #include <stdio.h>\\nvoid printFactors(int numb...   \n",
              "..                                                 ...   \n",
              "995  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "996  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "997  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "998  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "999  #include <stdio.h>\\n\\n#define ASCII_SIZE 128\\n...   \n",
              "\n",
              "                                       Code_with_Error  Total_Marks  \\\n",
              "0    #include <stdio.h>\\nvoid printFactors(int numb...          7.0   \n",
              "1    #include <stdio.h>\\nvoid printFactors(int numb...          8.0   \n",
              "2    #include <stdio.h>\\nvoid printFactors(int numb...          5.0   \n",
              "3    #include <stdio.h>\\n\\nvoid printFactors(int nu...          7.0   \n",
              "4    #include <stdio.h>\\n\\nvoid printFactors(int nu...          5.0   \n",
              "..                                                 ...          ...   \n",
              "995  #include <stdio.h> \\n\\n#define MAX_SIZE 100 \\n...          7.0   \n",
              "996  #include <stdio.h> \\n\\nchar getMaxOccurringCha...          6.0   \n",
              "997  #include <stdio.h> \\n\\nchar getMaxOccurringCha...          6.0   \n",
              "998  #include <stdio.h> \\n\\n#define ASCII_SIZE 128 ...          5.0   \n",
              "999  #include <stdio.h> \\n\\n#define ASCII_SIZE 128 ...          6.0   \n",
              "\n",
              "                                                merged  \n",
              "0    Print the factors of a number #include <stdio....  \n",
              "1    Print the factors of a number #include <stdio....  \n",
              "2    Print the factors of a number #include <stdio....  \n",
              "3    Print the factors of a number #include <stdio....  \n",
              "4    Print the factors of a number #include <stdio....  \n",
              "..                                                 ...  \n",
              "995  Print maximum Occurring Character in a String ...  \n",
              "996  Print maximum Occurring Character in a String ...  \n",
              "997  Print maximum Occurring Character in a String ...  \n",
              "998  Print maximum Occurring Character in a String ...  \n",
              "999  Print maximum Occurring Character in a String ...  \n",
              "\n",
              "[1000 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70f29ba1-f70c-4d34-a34c-3e5d974f6d23\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Correct_Code</th>\n",
              "      <th>Code_with_Error</th>\n",
              "      <th>Total_Marks</th>\n",
              "      <th>merged</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Print the factors of a number #include &lt;stdio....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Print the factors of a number #include &lt;stdio....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Print the factors of a number #include &lt;stdio....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Print the factors of a number #include &lt;stdio....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Print the factors of a number</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\nvoid printFactors(int numb...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\nvoid printFactors(int nu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Print the factors of a number #include &lt;stdio....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\n#define MAX_SIZE 100 \\n...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\nchar getMaxOccurringCha...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\nchar getMaxOccurringCha...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\n#define ASCII_SIZE 128 ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "      <td>#include &lt;stdio.h&gt;\\n\\n#define ASCII_SIZE 128\\n...</td>\n",
              "      <td>#include &lt;stdio.h&gt; \\n\\n#define ASCII_SIZE 128 ...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Print maximum Occurring Character in a String ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70f29ba1-f70c-4d34-a34c-3e5d974f6d23')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-70f29ba1-f70c-4d34-a34c-3e5d974f6d23 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-70f29ba1-f70c-4d34-a34c-3e5d974f6d23');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with empty strings\n",
        "code['merged'] = code['merged'].fillna('')"
      ],
      "metadata": {
        "id": "QNyuv6NB2t2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "roberta_model = TFRobertaModel.from_pretrained(\"roberta-base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-ISRliJ2vwp",
        "outputId": "251240d7-cfa1-424d-843c-7d576d5cd640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['roberta.embeddings.position_ids', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights or buffers of the TF 2.0 model TFRobertaModel were not initialized from the PyTorch model and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and convert the textual data to vectors\n",
        "X_text = code[\"merged\"].values\n",
        "y = code[\"Total_Marks\"].values"
      ],
      "metadata": {
        "id": "W0hF6h468tE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_vectors = []\n",
        "for text in X_text:\n",
        "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='tf', max_length=512, truncation=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    output = roberta_model(input_ids, attention_mask=attention_mask)[0][:, 0, :]\n",
        "    X_vectors.append(output.numpy())"
      ],
      "metadata": {
        "id": "SmKBI6CS8vAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_vectors = np.array(X_vectors)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "IAjNw7UG8w-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDAKgccf91Eq",
        "outputId": "162d7ac8-50d6-4721-909c-3f43adf90d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.04381751,  0.01298395, -0.06823917, ..., -0.01078259,\n",
              "         -0.06515283,  0.00736105]],\n",
              "\n",
              "       [[-0.03485741,  0.02759037, -0.0669408 , ...,  0.01000887,\n",
              "         -0.06539918,  0.01887213]],\n",
              "\n",
              "       [[-0.04260369,  0.00817573, -0.0670611 , ..., -0.01272669,\n",
              "         -0.06602035,  0.00926103]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.02076413,  0.02080108, -0.06215055, ..., -0.03736269,\n",
              "         -0.05828972,  0.02422302]],\n",
              "\n",
              "       [[-0.00893429,  0.01403939, -0.07219779, ..., -0.02958895,\n",
              "         -0.0384867 ,  0.01692103]],\n",
              "\n",
              "       [[-0.01983733,  0.01483572, -0.06987616, ..., -0.03227926,\n",
              "         -0.05074834,  0.02020183]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vectors, y, test_size=0.25, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "AsmDKhT2801A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=1))"
      ],
      "metadata": {
        "id": "S4f3p01L83Zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='mean_squared_error')\n"
      ],
      "metadata": {
        "id": "O6O2llIU8-Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64, callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWHAkK869BBw",
        "outputId": "dc84c661-5f94-4ce2-ac6a-dc047b5e9f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 4.4392 - val_loss: 5.3367\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.2852 - val_loss: 5.3104\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.6058 - val_loss: 5.2253\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 4.4236 - val_loss: 5.1936\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.4240 - val_loss: 5.2030\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.3508 - val_loss: 5.1949\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.2858 - val_loss: 5.1878\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.4024 - val_loss: 5.1059\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.3588 - val_loss: 5.0771\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 4.1960 - val_loss: 5.0901\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.3470 - val_loss: 5.0662\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 4.3244 - val_loss: 5.0173\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.2648 - val_loss: 4.9990\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.3193 - val_loss: 4.9725\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 27ms/step - loss: 4.3053 - val_loss: 4.9535\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 40ms/step - loss: 4.1317 - val_loss: 4.9946\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 36ms/step - loss: 4.2505 - val_loss: 4.9143\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 32ms/step - loss: 4.1733 - val_loss: 4.9187\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 26ms/step - loss: 4.1936 - val_loss: 4.8903\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 4.3141 - val_loss: 4.8529\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 4.1273 - val_loss: 4.8594\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 4.1471 - val_loss: 4.8321\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.3568 - val_loss: 4.8066\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 4.1296 - val_loss: 4.8586\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.1756 - val_loss: 4.7913\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.0677 - val_loss: 4.7729\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.1358 - val_loss: 4.8035\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 4.0016 - val_loss: 4.7430\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 4.0417 - val_loss: 4.7390\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.1253 - val_loss: 4.7202\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 4.0523 - val_loss: 4.7234\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 4.0314 - val_loss: 4.6897\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.9674 - val_loss: 4.7005\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 4.1127 - val_loss: 4.6754\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.9336 - val_loss: 4.6762\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.8015 - val_loss: 4.6478\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 4.0467 - val_loss: 4.6264\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.9902 - val_loss: 4.6266\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.8773 - val_loss: 4.6091\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 18ms/step - loss: 3.8437 - val_loss: 4.6123\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.9999 - val_loss: 4.5908\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.9882 - val_loss: 4.6024\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 22ms/step - loss: 3.9437 - val_loss: 4.5879\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.8927 - val_loss: 4.5713\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.7272 - val_loss: 4.5550\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.8475 - val_loss: 4.5620\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 21ms/step - loss: 3.7591 - val_loss: 4.5660\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.8456 - val_loss: 4.5465\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 19ms/step - loss: 3.8188 - val_loss: 4.5329\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 20ms/step - loss: 3.7247 - val_loss: 4.5336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKQY1w3V5HdM",
        "outputId": "f55fe96f-e7c6-4132-db7f-c5715fde9d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18/18 [==============================] - 1s 6ms/step\n",
            "8/8 [==============================] - 0s 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "train_mape = mean_absolute_percentage_error(y_train, y_train_pred)\n",
        "test_mape = mean_absolute_percentage_error(y_test, y_test_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "vlardTCZ9Gjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metrics\n",
        "print(\"Train RMSE:\", train_rmse)\n",
        "print(\"Test RMSE:\", test_rmse)\n",
        "print() \n",
        "print(\"Train MAE:\", train_mae)\n",
        "print(\"Test MAE:\", test_mae)\n",
        "print() \n",
        "print(\"Train MAPE:\", train_mape)\n",
        "print(\"Test MAPE:\", test_mape)\n",
        "print() \n",
        "print(\"Train R^2:\", train_r2)\n",
        "print(\"Test R^2:\", test_r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQMFl8kS9LqS",
        "outputId": "4716647a-d677-41ea-8636-38c5fe571ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train RMSE: 2.0840238739886017\n",
            "Test RMSE: 2.192497845908926\n",
            "\n",
            "Train MAE: 1.6558579601002759\n",
            "Test MAE: 1.7370490894317627\n",
            "\n",
            "Train MAPE: 95916035021653.16\n",
            "Test MAPE: 331366081325171.06\n",
            "\n",
            "Train R^2: 0.10303816805624522\n",
            "Test R^2: 0.09377673600009351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyforest\n",
        "!pip install lazypredict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGS_FEDR937r",
        "outputId": "bb863143-d737-4752-b105-3fa0783df2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyforest\n",
            "  Downloading pyforest-1.1.0.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyforest\n",
            "  Building wheel for pyforest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyforest: filename=pyforest-1.1.0-py2.py3-none-any.whl size=14606 sha256=7f6a80f02c602dd6b9ebd0e131546fb49c71c4ca3fc82574ffc844b9656ed277\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/7d/2c/5d2f5e62de376c386fd3bf5a8e5bd119ace6a9f48f49df6017\n",
            "Successfully built pyforest\n",
            "Installing collected packages: pyforest\n",
            "Successfully installed pyforest-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lazypredict\n",
            "  Downloading lazypredict-0.2.12-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from lazypredict) (8.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.2.0)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (from lazypredict) (3.3.5)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (from lazypredict) (1.7.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm->lazypredict) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lazypredict) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->lazypredict) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->lazypredict) (1.16.0)\n",
            "Installing collected packages: lazypredict\n",
            "Successfully installed lazypredict-0.2.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing important libraries\n",
        "import pyforest\n",
        "from lazypredict.Supervised import LazyRegressor\n",
        "from pandas.plotting import scatter_matrix\n",
        "# Scikit-learn packages\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "# Hide warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# Setting up max columns displayed to 100\n",
        "pd.options.display.max_columns = 100"
      ],
      "metadata": {
        "id": "ksUDsWUSG74r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the X_train and X_test arrays\n",
        "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)"
      ],
      "metadata": {
        "id": "gnGbHg3eHIuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LazyRegressor(ignore_warnings=False, custom_metric=None)\n",
        "models, predictions = reg.fit(X_train_reshaped, X_test_reshaped, y_train, y_test)\n",
        "print(models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6_sUdj0HA3m",
        "outputId": "d1df1f02-2dce-4c09-89e5-d882fabfec53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██▏       | 9/42 [01:38<07:50, 14.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GammaRegressor model failed to execute\n",
            "Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 24/42 [03:40<01:48,  6.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LassoLarsIC model failed to execute\n",
            "You are using LassoLarsIC in the case where the number of samples is smaller than the number of features. In this setting, getting a good estimate for the variance of the noise is not possible. Provide an estimate of the noise variance in the constructor.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 32/42 [03:56<00:35,  3.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor model failed to execute\n",
            "`min_samples` may not be larger than number of samples: n_samples = 562.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42/42 [04:38<00:00,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Adjusted R-Squared       R-Squared      RMSE  \\\n",
            "Model                                                                         \n",
            "SGDRegressor                       15935008286.95 -33213932932.37 419741.32   \n",
            "Lars                                     75215.29      -156770.95    911.92   \n",
            "TransformedTargetRegressor                  12.03          -21.99     11.04   \n",
            "LinearRegression                            12.03          -21.99     11.04   \n",
            "KernelRidge                                  5.46           -8.29      7.02   \n",
            "GaussianProcessRegressor                     4.50           -6.29      6.22   \n",
            "Ridge                                        1.68           -0.43      2.75   \n",
            "LinearSVR                                    1.64           -0.33      2.66   \n",
            "ExtraTreeRegressor                           1.60           -0.25      2.58   \n",
            "DecisionTreeRegressor                        1.58           -0.21      2.53   \n",
            "PassiveAggressiveRegressor                   1.57           -0.19      2.51   \n",
            "OrthogonalMatchingPursuit                    1.53           -0.10      2.42   \n",
            "HuberRegressor                               1.50           -0.05      2.36   \n",
            "QuantileRegressor                            1.49           -0.01      2.32   \n",
            "Lasso                                        1.48           -0.00      2.30   \n",
            "LassoLars                                    1.48           -0.00      2.30   \n",
            "DummyRegressor                               1.48           -0.00      2.30   \n",
            "ElasticNet                                   1.46            0.04      2.26   \n",
            "LarsCV                                       1.46            0.04      2.25   \n",
            "KNeighborsRegressor                          1.46            0.04      2.25   \n",
            "MLPRegressor                                 1.41            0.15      2.12   \n",
            "AdaBoostRegressor                            1.40            0.17      2.09   \n",
            "RidgeCV                                      1.39            0.18      2.09   \n",
            "OrthogonalMatchingPursuitCV                  1.39            0.18      2.08   \n",
            "NuSVR                                        1.38            0.21      2.04   \n",
            "BaggingRegressor                             1.37            0.22      2.04   \n",
            "XGBRegressor                                 1.37            0.23      2.03   \n",
            "SVR                                          1.37            0.23      2.02   \n",
            "LassoLarsCV                                  1.35            0.26      1.98   \n",
            "LassoCV                                      1.35            0.26      1.98   \n",
            "ElasticNetCV                                 1.35            0.27      1.96   \n",
            "BayesianRidge                                1.35            0.27      1.96   \n",
            "TweedieRegressor                             1.34            0.29      1.95   \n",
            "PoissonRegressor                             1.34            0.29      1.94   \n",
            "GradientBoostingRegressor                    1.33            0.31      1.92   \n",
            "RandomForestRegressor                        1.33            0.32      1.90   \n",
            "LGBMRegressor                                1.33            0.32      1.90   \n",
            "ExtraTreesRegressor                          1.33            0.32      1.90   \n",
            "HistGradientBoostingRegressor                1.32            0.34      1.87   \n",
            "\n",
            "                               Time Taken  \n",
            "Model                                      \n",
            "SGDRegressor                         0.15  \n",
            "Lars                                 0.46  \n",
            "TransformedTargetRegressor           0.34  \n",
            "LinearRegression                     0.18  \n",
            "KernelRidge                          0.10  \n",
            "GaussianProcessRegressor             0.58  \n",
            "Ridge                                0.09  \n",
            "LinearSVR                            1.25  \n",
            "ExtraTreeRegressor                   0.17  \n",
            "DecisionTreeRegressor                0.47  \n",
            "PassiveAggressiveRegressor           0.15  \n",
            "OrthogonalMatchingPursuit            0.07  \n",
            "HuberRegressor                       0.38  \n",
            "QuantileRegressor                    9.37  \n",
            "Lasso                                0.06  \n",
            "LassoLars                            0.15  \n",
            "DummyRegressor                       0.07  \n",
            "ElasticNet                           0.08  \n",
            "LarsCV                               3.44  \n",
            "KNeighborsRegressor                  0.13  \n",
            "MLPRegressor                         3.15  \n",
            "AdaBoostRegressor                    2.37  \n",
            "RidgeCV                              0.42  \n",
            "OrthogonalMatchingPursuitCV          0.33  \n",
            "NuSVR                                0.19  \n",
            "BaggingRegressor                     3.35  \n",
            "XGBRegressor                         9.28  \n",
            "SVR                                  0.35  \n",
            "LassoLarsCV                          5.01  \n",
            "LassoCV                             69.07  \n",
            "ElasticNetCV                        84.22  \n",
            "BayesianRidge                        0.37  \n",
            "TweedieRegressor                     0.84  \n",
            "PoissonRegressor                     1.32  \n",
            "GradientBoostingRegressor           16.28  \n",
            "RandomForestRegressor               23.46  \n",
            "LGBMRegressor                        7.35  \n",
            "ExtraTreesRegressor                  7.42  \n",
            "HistGradientBoostingRegressor       25.77  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "\n",
        "# Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor()\n",
        "rf_regressor.fit(X_train_reshaped, y_train)\n",
        "y_train_pred_rf = rf_regressor.predict(X_train_reshaped)\n",
        "y_test_pred_rf = rf_regressor.predict(X_test_reshaped)\n",
        "\n",
        "# Gradient Boosting Regressor\n",
        "gra_regressor = GradientBoostingRegressor()\n",
        "gra_regressor.fit(X_train_reshaped, y_train)\n",
        "y_train_pred_gra = gra_regressor.predict(X_train_reshaped)\n",
        "y_test_pred_gra = gra_regressor.predict(X_test_reshaped)\n",
        "\n",
        "# ExtraTreesRegressor\n",
        "et_regressor = ExtraTreesRegressor()\n",
        "et_regressor.fit(X_train_reshaped, y_train)\n",
        "y_train_pred_et = et_regressor.predict(X_train_reshaped)\n",
        "y_test_pred_et = et_regressor.predict(X_test_reshaped)\n",
        "\n",
        "# CatBoost Regressor\n",
        "catboost_regressor = CatBoostRegressor()\n",
        "catboost_regressor.fit(X_train_reshaped, y_train)\n",
        "y_train_pred_catboost = catboost_regressor.predict(X_train_reshaped)\n",
        "y_test_pred_catboost = catboost_regressor.predict(X_test_reshaped)\n",
        "\n",
        "# LGBM Regressor\n",
        "xgb_regressor = lgb.LGBMRegressor()\n",
        "xgb_regressor.fit(X_train_reshaped, y_train)\n",
        "y_train_pred_xgb = xgb_regressor.predict(X_train_reshaped)\n",
        "y_test_pred_xgb = xgb_regressor.predict(X_test_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXtn7URRHJgJ",
        "outputId": "bb89cd0b-f55d-47ce-bbb1-efa5c576aa09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate set to 0.03738\n",
            "0:\tlearn: 2.1841532\ttotal: 394ms\tremaining: 6m 33s\n",
            "1:\tlearn: 2.1639475\ttotal: 585ms\tremaining: 4m 51s\n",
            "2:\tlearn: 2.1453095\ttotal: 777ms\tremaining: 4m 18s\n",
            "3:\tlearn: 2.1284584\ttotal: 961ms\tremaining: 3m 59s\n",
            "4:\tlearn: 2.1118236\ttotal: 1.14s\tremaining: 3m 47s\n",
            "5:\tlearn: 2.0974882\ttotal: 1.34s\tremaining: 3m 41s\n",
            "6:\tlearn: 2.0853071\ttotal: 1.53s\tremaining: 3m 37s\n",
            "7:\tlearn: 2.0672525\ttotal: 1.72s\tremaining: 3m 33s\n",
            "8:\tlearn: 2.0548193\ttotal: 1.92s\tremaining: 3m 31s\n",
            "9:\tlearn: 2.0419752\ttotal: 2.1s\tremaining: 3m 28s\n",
            "10:\tlearn: 2.0313450\ttotal: 2.29s\tremaining: 3m 26s\n",
            "11:\tlearn: 2.0165697\ttotal: 2.49s\tremaining: 3m 24s\n",
            "12:\tlearn: 2.0063117\ttotal: 2.68s\tremaining: 3m 23s\n",
            "13:\tlearn: 1.9919981\ttotal: 2.87s\tremaining: 3m 21s\n",
            "14:\tlearn: 1.9785031\ttotal: 3.05s\tremaining: 3m 20s\n",
            "15:\tlearn: 1.9660864\ttotal: 3.23s\tremaining: 3m 18s\n",
            "16:\tlearn: 1.9516961\ttotal: 3.43s\tremaining: 3m 18s\n",
            "17:\tlearn: 1.9415135\ttotal: 3.62s\tremaining: 3m 17s\n",
            "18:\tlearn: 1.9268139\ttotal: 3.81s\tremaining: 3m 16s\n",
            "19:\tlearn: 1.9155224\ttotal: 3.99s\tremaining: 3m 15s\n",
            "20:\tlearn: 1.9053986\ttotal: 4.18s\tremaining: 3m 14s\n",
            "21:\tlearn: 1.8951129\ttotal: 4.37s\tremaining: 3m 14s\n",
            "22:\tlearn: 1.8842962\ttotal: 4.57s\tremaining: 3m 14s\n",
            "23:\tlearn: 1.8759652\ttotal: 4.76s\tremaining: 3m 13s\n",
            "24:\tlearn: 1.8646658\ttotal: 4.95s\tremaining: 3m 13s\n",
            "25:\tlearn: 1.8571217\ttotal: 5.14s\tremaining: 3m 12s\n",
            "26:\tlearn: 1.8487450\ttotal: 5.33s\tremaining: 3m 12s\n",
            "27:\tlearn: 1.8391151\ttotal: 5.54s\tremaining: 3m 12s\n",
            "28:\tlearn: 1.8306383\ttotal: 5.74s\tremaining: 3m 12s\n",
            "29:\tlearn: 1.8237645\ttotal: 6.05s\tremaining: 3m 15s\n",
            "30:\tlearn: 1.8161881\ttotal: 6.4s\tremaining: 3m 20s\n",
            "31:\tlearn: 1.8077050\ttotal: 6.78s\tremaining: 3m 24s\n",
            "32:\tlearn: 1.8033036\ttotal: 7.14s\tremaining: 3m 29s\n",
            "33:\tlearn: 1.7951143\ttotal: 7.51s\tremaining: 3m 33s\n",
            "34:\tlearn: 1.7885017\ttotal: 7.88s\tremaining: 3m 37s\n",
            "35:\tlearn: 1.7792132\ttotal: 8.25s\tremaining: 3m 40s\n",
            "36:\tlearn: 1.7691925\ttotal: 8.64s\tremaining: 3m 44s\n",
            "37:\tlearn: 1.7618194\ttotal: 9.02s\tremaining: 3m 48s\n",
            "38:\tlearn: 1.7545711\ttotal: 9.38s\tremaining: 3m 51s\n",
            "39:\tlearn: 1.7494243\ttotal: 9.75s\tremaining: 3m 54s\n",
            "40:\tlearn: 1.7425696\ttotal: 10.1s\tremaining: 3m 55s\n",
            "41:\tlearn: 1.7375950\ttotal: 10.3s\tremaining: 3m 54s\n",
            "42:\tlearn: 1.7290217\ttotal: 10.5s\tremaining: 3m 52s\n",
            "43:\tlearn: 1.7223100\ttotal: 10.7s\tremaining: 3m 51s\n",
            "44:\tlearn: 1.7160294\ttotal: 10.9s\tremaining: 3m 50s\n",
            "45:\tlearn: 1.7103240\ttotal: 11s\tremaining: 3m 49s\n",
            "46:\tlearn: 1.7034732\ttotal: 11.2s\tremaining: 3m 47s\n",
            "47:\tlearn: 1.6980089\ttotal: 11.4s\tremaining: 3m 46s\n",
            "48:\tlearn: 1.6936002\ttotal: 11.6s\tremaining: 3m 45s\n",
            "49:\tlearn: 1.6881312\ttotal: 11.8s\tremaining: 3m 44s\n",
            "50:\tlearn: 1.6822051\ttotal: 12s\tremaining: 3m 43s\n",
            "51:\tlearn: 1.6761721\ttotal: 12.2s\tremaining: 3m 42s\n",
            "52:\tlearn: 1.6706403\ttotal: 12.4s\tremaining: 3m 41s\n",
            "53:\tlearn: 1.6633260\ttotal: 12.6s\tremaining: 3m 40s\n",
            "54:\tlearn: 1.6572996\ttotal: 12.8s\tremaining: 3m 40s\n",
            "55:\tlearn: 1.6530072\ttotal: 13s\tremaining: 3m 39s\n",
            "56:\tlearn: 1.6482832\ttotal: 13.2s\tremaining: 3m 38s\n",
            "57:\tlearn: 1.6439657\ttotal: 13.4s\tremaining: 3m 37s\n",
            "58:\tlearn: 1.6383263\ttotal: 13.6s\tremaining: 3m 36s\n",
            "59:\tlearn: 1.6344427\ttotal: 13.8s\tremaining: 3m 36s\n",
            "60:\tlearn: 1.6289049\ttotal: 14s\tremaining: 3m 35s\n",
            "61:\tlearn: 1.6245735\ttotal: 14.2s\tremaining: 3m 34s\n",
            "62:\tlearn: 1.6200180\ttotal: 14.4s\tremaining: 3m 33s\n",
            "63:\tlearn: 1.6175082\ttotal: 14.6s\tremaining: 3m 32s\n",
            "64:\tlearn: 1.6121546\ttotal: 14.8s\tremaining: 3m 32s\n",
            "65:\tlearn: 1.6059705\ttotal: 14.9s\tremaining: 3m 31s\n",
            "66:\tlearn: 1.6013941\ttotal: 15.1s\tremaining: 3m 30s\n",
            "67:\tlearn: 1.5956346\ttotal: 15.3s\tremaining: 3m 30s\n",
            "68:\tlearn: 1.5920552\ttotal: 15.5s\tremaining: 3m 29s\n",
            "69:\tlearn: 1.5870906\ttotal: 15.7s\tremaining: 3m 28s\n",
            "70:\tlearn: 1.5837528\ttotal: 15.9s\tremaining: 3m 28s\n",
            "71:\tlearn: 1.5813347\ttotal: 16.1s\tremaining: 3m 27s\n",
            "72:\tlearn: 1.5754671\ttotal: 16.3s\tremaining: 3m 26s\n",
            "73:\tlearn: 1.5703682\ttotal: 16.5s\tremaining: 3m 26s\n",
            "74:\tlearn: 1.5650568\ttotal: 16.7s\tremaining: 3m 25s\n",
            "75:\tlearn: 1.5608333\ttotal: 16.9s\tremaining: 3m 25s\n",
            "76:\tlearn: 1.5577740\ttotal: 17.1s\tremaining: 3m 24s\n",
            "77:\tlearn: 1.5525466\ttotal: 17.3s\tremaining: 3m 24s\n",
            "78:\tlearn: 1.5496291\ttotal: 17.5s\tremaining: 3m 23s\n",
            "79:\tlearn: 1.5470868\ttotal: 17.7s\tremaining: 3m 23s\n",
            "80:\tlearn: 1.5431647\ttotal: 17.9s\tremaining: 3m 22s\n",
            "81:\tlearn: 1.5401975\ttotal: 18.1s\tremaining: 3m 22s\n",
            "82:\tlearn: 1.5372331\ttotal: 18.3s\tremaining: 3m 21s\n",
            "83:\tlearn: 1.5330765\ttotal: 18.5s\tremaining: 3m 21s\n",
            "84:\tlearn: 1.5293164\ttotal: 18.7s\tremaining: 3m 20s\n",
            "85:\tlearn: 1.5243764\ttotal: 18.8s\tremaining: 3m 20s\n",
            "86:\tlearn: 1.5208966\ttotal: 19s\tremaining: 3m 19s\n",
            "87:\tlearn: 1.5171123\ttotal: 19.2s\tremaining: 3m 19s\n",
            "88:\tlearn: 1.5125448\ttotal: 19.4s\tremaining: 3m 18s\n",
            "89:\tlearn: 1.5077167\ttotal: 19.6s\tremaining: 3m 18s\n",
            "90:\tlearn: 1.5061145\ttotal: 19.8s\tremaining: 3m 17s\n",
            "91:\tlearn: 1.5040499\ttotal: 20s\tremaining: 3m 17s\n",
            "92:\tlearn: 1.5005813\ttotal: 20.6s\tremaining: 3m 21s\n",
            "93:\tlearn: 1.4982371\ttotal: 21.7s\tremaining: 3m 29s\n",
            "94:\tlearn: 1.4951206\ttotal: 22.1s\tremaining: 3m 30s\n",
            "95:\tlearn: 1.4903039\ttotal: 22.5s\tremaining: 3m 31s\n",
            "96:\tlearn: 1.4868803\ttotal: 22.8s\tremaining: 3m 32s\n",
            "97:\tlearn: 1.4843092\ttotal: 23.1s\tremaining: 3m 33s\n",
            "98:\tlearn: 1.4795186\ttotal: 23.6s\tremaining: 3m 34s\n",
            "99:\tlearn: 1.4763398\ttotal: 23.9s\tremaining: 3m 35s\n",
            "100:\tlearn: 1.4728327\ttotal: 24.3s\tremaining: 3m 36s\n",
            "101:\tlearn: 1.4698098\ttotal: 24.7s\tremaining: 3m 37s\n",
            "102:\tlearn: 1.4661362\ttotal: 24.9s\tremaining: 3m 37s\n",
            "103:\tlearn: 1.4605553\ttotal: 25.1s\tremaining: 3m 36s\n",
            "104:\tlearn: 1.4574874\ttotal: 25.3s\tremaining: 3m 35s\n",
            "105:\tlearn: 1.4540744\ttotal: 25.5s\tremaining: 3m 35s\n",
            "106:\tlearn: 1.4504620\ttotal: 25.7s\tremaining: 3m 34s\n",
            "107:\tlearn: 1.4466458\ttotal: 25.9s\tremaining: 3m 33s\n",
            "108:\tlearn: 1.4427389\ttotal: 26.1s\tremaining: 3m 33s\n",
            "109:\tlearn: 1.4400496\ttotal: 26.3s\tremaining: 3m 32s\n",
            "110:\tlearn: 1.4347966\ttotal: 26.5s\tremaining: 3m 32s\n",
            "111:\tlearn: 1.4323743\ttotal: 26.7s\tremaining: 3m 31s\n",
            "112:\tlearn: 1.4287044\ttotal: 26.9s\tremaining: 3m 30s\n",
            "113:\tlearn: 1.4270192\ttotal: 27s\tremaining: 3m 30s\n",
            "114:\tlearn: 1.4223766\ttotal: 27.2s\tremaining: 3m 29s\n",
            "115:\tlearn: 1.4202372\ttotal: 27.4s\tremaining: 3m 29s\n",
            "116:\tlearn: 1.4179563\ttotal: 27.6s\tremaining: 3m 28s\n",
            "117:\tlearn: 1.4138620\ttotal: 27.8s\tremaining: 3m 27s\n",
            "118:\tlearn: 1.4108594\ttotal: 28s\tremaining: 3m 27s\n",
            "119:\tlearn: 1.4082371\ttotal: 28.2s\tremaining: 3m 26s\n",
            "120:\tlearn: 1.4051107\ttotal: 28.4s\tremaining: 3m 26s\n",
            "121:\tlearn: 1.4015355\ttotal: 28.6s\tremaining: 3m 25s\n",
            "122:\tlearn: 1.3980690\ttotal: 28.8s\tremaining: 3m 25s\n",
            "123:\tlearn: 1.3943715\ttotal: 29s\tremaining: 3m 24s\n",
            "124:\tlearn: 1.3907720\ttotal: 29.2s\tremaining: 3m 24s\n",
            "125:\tlearn: 1.3891497\ttotal: 29.4s\tremaining: 3m 23s\n",
            "126:\tlearn: 1.3851847\ttotal: 29.6s\tremaining: 3m 23s\n",
            "127:\tlearn: 1.3803734\ttotal: 29.7s\tremaining: 3m 22s\n",
            "128:\tlearn: 1.3779400\ttotal: 29.9s\tremaining: 3m 22s\n",
            "129:\tlearn: 1.3757606\ttotal: 30.1s\tremaining: 3m 21s\n",
            "130:\tlearn: 1.3727474\ttotal: 30.3s\tremaining: 3m 21s\n",
            "131:\tlearn: 1.3708513\ttotal: 30.5s\tremaining: 3m 20s\n",
            "132:\tlearn: 1.3662199\ttotal: 30.7s\tremaining: 3m 20s\n",
            "133:\tlearn: 1.3627544\ttotal: 30.9s\tremaining: 3m 19s\n",
            "134:\tlearn: 1.3592431\ttotal: 31.1s\tremaining: 3m 19s\n",
            "135:\tlearn: 1.3556816\ttotal: 31.3s\tremaining: 3m 18s\n",
            "136:\tlearn: 1.3531818\ttotal: 31.5s\tremaining: 3m 18s\n",
            "137:\tlearn: 1.3506966\ttotal: 31.7s\tremaining: 3m 17s\n",
            "138:\tlearn: 1.3473420\ttotal: 31.9s\tremaining: 3m 17s\n",
            "139:\tlearn: 1.3438390\ttotal: 32s\tremaining: 3m 16s\n",
            "140:\tlearn: 1.3419470\ttotal: 32.2s\tremaining: 3m 16s\n",
            "141:\tlearn: 1.3394088\ttotal: 32.4s\tremaining: 3m 15s\n",
            "142:\tlearn: 1.3367134\ttotal: 32.6s\tremaining: 3m 15s\n",
            "143:\tlearn: 1.3339185\ttotal: 32.8s\tremaining: 3m 15s\n",
            "144:\tlearn: 1.3315187\ttotal: 33s\tremaining: 3m 14s\n",
            "145:\tlearn: 1.3290526\ttotal: 33.2s\tremaining: 3m 14s\n",
            "146:\tlearn: 1.3249379\ttotal: 33.4s\tremaining: 3m 13s\n",
            "147:\tlearn: 1.3205484\ttotal: 33.6s\tremaining: 3m 13s\n",
            "148:\tlearn: 1.3192202\ttotal: 33.8s\tremaining: 3m 12s\n",
            "149:\tlearn: 1.3166854\ttotal: 34s\tremaining: 3m 12s\n",
            "150:\tlearn: 1.3126052\ttotal: 34.1s\tremaining: 3m 12s\n",
            "151:\tlearn: 1.3106479\ttotal: 34.4s\tremaining: 3m 11s\n",
            "152:\tlearn: 1.3081940\ttotal: 34.5s\tremaining: 3m 11s\n",
            "153:\tlearn: 1.3051011\ttotal: 34.7s\tremaining: 3m 10s\n",
            "154:\tlearn: 1.3035042\ttotal: 35s\tremaining: 3m 10s\n",
            "155:\tlearn: 1.3010099\ttotal: 35.3s\tremaining: 3m 11s\n",
            "156:\tlearn: 1.2983266\ttotal: 35.7s\tremaining: 3m 11s\n",
            "157:\tlearn: 1.2961626\ttotal: 36s\tremaining: 3m 12s\n",
            "158:\tlearn: 1.2931795\ttotal: 36.5s\tremaining: 3m 13s\n",
            "159:\tlearn: 1.2912633\ttotal: 36.8s\tremaining: 3m 13s\n",
            "160:\tlearn: 1.2890630\ttotal: 37.2s\tremaining: 3m 13s\n",
            "161:\tlearn: 1.2871558\ttotal: 37.6s\tremaining: 3m 14s\n",
            "162:\tlearn: 1.2854085\ttotal: 37.9s\tremaining: 3m 14s\n",
            "163:\tlearn: 1.2831819\ttotal: 38.3s\tremaining: 3m 15s\n",
            "164:\tlearn: 1.2814204\ttotal: 38.7s\tremaining: 3m 15s\n",
            "165:\tlearn: 1.2777984\ttotal: 39.1s\tremaining: 3m 16s\n",
            "166:\tlearn: 1.2762751\ttotal: 39.3s\tremaining: 3m 16s\n",
            "167:\tlearn: 1.2744175\ttotal: 39.5s\tremaining: 3m 15s\n",
            "168:\tlearn: 1.2722842\ttotal: 39.7s\tremaining: 3m 15s\n",
            "169:\tlearn: 1.2694717\ttotal: 39.9s\tremaining: 3m 14s\n",
            "170:\tlearn: 1.2668981\ttotal: 40.1s\tremaining: 3m 14s\n",
            "171:\tlearn: 1.2646339\ttotal: 40.3s\tremaining: 3m 13s\n",
            "172:\tlearn: 1.2631409\ttotal: 40.4s\tremaining: 3m 13s\n",
            "173:\tlearn: 1.2615246\ttotal: 40.6s\tremaining: 3m 12s\n",
            "174:\tlearn: 1.2586563\ttotal: 40.8s\tremaining: 3m 12s\n",
            "175:\tlearn: 1.2562909\ttotal: 41s\tremaining: 3m 12s\n",
            "176:\tlearn: 1.2543038\ttotal: 41.2s\tremaining: 3m 11s\n",
            "177:\tlearn: 1.2530648\ttotal: 41.4s\tremaining: 3m 11s\n",
            "178:\tlearn: 1.2506971\ttotal: 41.6s\tremaining: 3m 10s\n",
            "179:\tlearn: 1.2491482\ttotal: 41.8s\tremaining: 3m 10s\n",
            "180:\tlearn: 1.2456300\ttotal: 42s\tremaining: 3m 9s\n",
            "181:\tlearn: 1.2435482\ttotal: 42.2s\tremaining: 3m 9s\n",
            "182:\tlearn: 1.2408152\ttotal: 42.4s\tremaining: 3m 9s\n",
            "183:\tlearn: 1.2362277\ttotal: 42.6s\tremaining: 3m 8s\n",
            "184:\tlearn: 1.2336581\ttotal: 42.8s\tremaining: 3m 8s\n",
            "185:\tlearn: 1.2318730\ttotal: 43s\tremaining: 3m 7s\n",
            "186:\tlearn: 1.2277983\ttotal: 43.1s\tremaining: 3m 7s\n",
            "187:\tlearn: 1.2262582\ttotal: 43.3s\tremaining: 3m 7s\n",
            "188:\tlearn: 1.2235838\ttotal: 43.5s\tremaining: 3m 6s\n",
            "189:\tlearn: 1.2215638\ttotal: 43.7s\tremaining: 3m 6s\n",
            "190:\tlearn: 1.2183505\ttotal: 43.9s\tremaining: 3m 5s\n",
            "191:\tlearn: 1.2159405\ttotal: 44.1s\tremaining: 3m 5s\n",
            "192:\tlearn: 1.2139581\ttotal: 44.3s\tremaining: 3m 5s\n",
            "193:\tlearn: 1.2118905\ttotal: 44.5s\tremaining: 3m 4s\n",
            "194:\tlearn: 1.2105863\ttotal: 44.7s\tremaining: 3m 4s\n",
            "195:\tlearn: 1.2085141\ttotal: 44.9s\tremaining: 3m 4s\n",
            "196:\tlearn: 1.2060461\ttotal: 45.1s\tremaining: 3m 3s\n",
            "197:\tlearn: 1.2043090\ttotal: 45.2s\tremaining: 3m 3s\n",
            "198:\tlearn: 1.2024531\ttotal: 45.4s\tremaining: 3m 2s\n",
            "199:\tlearn: 1.1999924\ttotal: 45.6s\tremaining: 3m 2s\n",
            "200:\tlearn: 1.1983905\ttotal: 45.8s\tremaining: 3m 2s\n",
            "201:\tlearn: 1.1954175\ttotal: 46s\tremaining: 3m 1s\n",
            "202:\tlearn: 1.1927024\ttotal: 46.2s\tremaining: 3m 1s\n",
            "203:\tlearn: 1.1900953\ttotal: 46.4s\tremaining: 3m\n",
            "204:\tlearn: 1.1886362\ttotal: 46.6s\tremaining: 3m\n",
            "205:\tlearn: 1.1867314\ttotal: 46.8s\tremaining: 3m\n",
            "206:\tlearn: 1.1852225\ttotal: 47s\tremaining: 2m 59s\n",
            "207:\tlearn: 1.1835887\ttotal: 47.1s\tremaining: 2m 59s\n",
            "208:\tlearn: 1.1816664\ttotal: 47.3s\tremaining: 2m 59s\n",
            "209:\tlearn: 1.1802125\ttotal: 47.5s\tremaining: 2m 58s\n",
            "210:\tlearn: 1.1784299\ttotal: 47.7s\tremaining: 2m 58s\n",
            "211:\tlearn: 1.1767519\ttotal: 47.9s\tremaining: 2m 58s\n",
            "212:\tlearn: 1.1751899\ttotal: 48.1s\tremaining: 2m 57s\n",
            "213:\tlearn: 1.1738164\ttotal: 48.3s\tremaining: 2m 57s\n",
            "214:\tlearn: 1.1725398\ttotal: 48.5s\tremaining: 2m 56s\n",
            "215:\tlearn: 1.1713092\ttotal: 48.6s\tremaining: 2m 56s\n",
            "216:\tlearn: 1.1688592\ttotal: 48.8s\tremaining: 2m 56s\n",
            "217:\tlearn: 1.1669962\ttotal: 49s\tremaining: 2m 55s\n",
            "218:\tlearn: 1.1649245\ttotal: 49.2s\tremaining: 2m 55s\n",
            "219:\tlearn: 1.1627892\ttotal: 49.6s\tremaining: 2m 55s\n",
            "220:\tlearn: 1.1614064\ttotal: 50s\tremaining: 2m 56s\n",
            "221:\tlearn: 1.1591400\ttotal: 50.3s\tremaining: 2m 56s\n",
            "222:\tlearn: 1.1565241\ttotal: 50.7s\tremaining: 2m 56s\n",
            "223:\tlearn: 1.1534677\ttotal: 51s\tremaining: 2m 56s\n",
            "224:\tlearn: 1.1527766\ttotal: 51.4s\tremaining: 2m 57s\n",
            "225:\tlearn: 1.1484809\ttotal: 51.8s\tremaining: 2m 57s\n",
            "226:\tlearn: 1.1451981\ttotal: 52.2s\tremaining: 2m 57s\n",
            "227:\tlearn: 1.1434001\ttotal: 52.5s\tremaining: 2m 57s\n",
            "228:\tlearn: 1.1392359\ttotal: 52.7s\tremaining: 2m 57s\n",
            "229:\tlearn: 1.1375750\ttotal: 52.9s\tremaining: 2m 56s\n",
            "230:\tlearn: 1.1362757\ttotal: 53.1s\tremaining: 2m 56s\n",
            "231:\tlearn: 1.1341342\ttotal: 53.2s\tremaining: 2m 56s\n",
            "232:\tlearn: 1.1330707\ttotal: 53.4s\tremaining: 2m 55s\n",
            "233:\tlearn: 1.1315838\ttotal: 53.6s\tremaining: 2m 55s\n",
            "234:\tlearn: 1.1303625\ttotal: 53.8s\tremaining: 2m 55s\n",
            "235:\tlearn: 1.1294151\ttotal: 54s\tremaining: 2m 54s\n",
            "236:\tlearn: 1.1261440\ttotal: 54.2s\tremaining: 2m 54s\n",
            "237:\tlearn: 1.1245467\ttotal: 54.4s\tremaining: 2m 54s\n",
            "238:\tlearn: 1.1214901\ttotal: 54.6s\tremaining: 2m 53s\n",
            "239:\tlearn: 1.1184117\ttotal: 54.8s\tremaining: 2m 53s\n",
            "240:\tlearn: 1.1148009\ttotal: 54.9s\tremaining: 2m 53s\n",
            "241:\tlearn: 1.1137884\ttotal: 55.1s\tremaining: 2m 52s\n",
            "242:\tlearn: 1.1117616\ttotal: 55.3s\tremaining: 2m 52s\n",
            "243:\tlearn: 1.1104277\ttotal: 55.5s\tremaining: 2m 52s\n",
            "244:\tlearn: 1.1086768\ttotal: 55.7s\tremaining: 2m 51s\n",
            "245:\tlearn: 1.1070036\ttotal: 55.9s\tremaining: 2m 51s\n",
            "246:\tlearn: 1.1049370\ttotal: 56.1s\tremaining: 2m 51s\n",
            "247:\tlearn: 1.1014593\ttotal: 56.3s\tremaining: 2m 50s\n",
            "248:\tlearn: 1.0982545\ttotal: 56.5s\tremaining: 2m 50s\n",
            "249:\tlearn: 1.0942893\ttotal: 56.7s\tremaining: 2m 49s\n",
            "250:\tlearn: 1.0915680\ttotal: 56.8s\tremaining: 2m 49s\n",
            "251:\tlearn: 1.0903798\ttotal: 57s\tremaining: 2m 49s\n",
            "252:\tlearn: 1.0892340\ttotal: 57.2s\tremaining: 2m 48s\n",
            "253:\tlearn: 1.0873248\ttotal: 57.4s\tremaining: 2m 48s\n",
            "254:\tlearn: 1.0860525\ttotal: 57.6s\tremaining: 2m 48s\n",
            "255:\tlearn: 1.0839601\ttotal: 57.8s\tremaining: 2m 47s\n",
            "256:\tlearn: 1.0824320\ttotal: 58s\tremaining: 2m 47s\n",
            "257:\tlearn: 1.0800020\ttotal: 58.2s\tremaining: 2m 47s\n",
            "258:\tlearn: 1.0781739\ttotal: 58.4s\tremaining: 2m 46s\n",
            "259:\tlearn: 1.0768113\ttotal: 58.6s\tremaining: 2m 46s\n",
            "260:\tlearn: 1.0748277\ttotal: 58.8s\tremaining: 2m 46s\n",
            "261:\tlearn: 1.0737238\ttotal: 58.9s\tremaining: 2m 46s\n",
            "262:\tlearn: 1.0708755\ttotal: 59.1s\tremaining: 2m 45s\n",
            "263:\tlearn: 1.0676256\ttotal: 59.3s\tremaining: 2m 45s\n",
            "264:\tlearn: 1.0637937\ttotal: 59.5s\tremaining: 2m 45s\n",
            "265:\tlearn: 1.0617194\ttotal: 59.7s\tremaining: 2m 44s\n",
            "266:\tlearn: 1.0592481\ttotal: 59.9s\tremaining: 2m 44s\n",
            "267:\tlearn: 1.0565068\ttotal: 1m\tremaining: 2m 44s\n",
            "268:\tlearn: 1.0539729\ttotal: 1m\tremaining: 2m 43s\n",
            "269:\tlearn: 1.0529999\ttotal: 1m\tremaining: 2m 43s\n",
            "270:\tlearn: 1.0486084\ttotal: 1m\tremaining: 2m 43s\n",
            "271:\tlearn: 1.0449287\ttotal: 1m\tremaining: 2m 42s\n",
            "272:\tlearn: 1.0433978\ttotal: 1m 1s\tremaining: 2m 42s\n",
            "273:\tlearn: 1.0405434\ttotal: 1m 1s\tremaining: 2m 42s\n",
            "274:\tlearn: 1.0387370\ttotal: 1m 1s\tremaining: 2m 41s\n",
            "275:\tlearn: 1.0364772\ttotal: 1m 1s\tremaining: 2m 41s\n",
            "276:\tlearn: 1.0352826\ttotal: 1m 1s\tremaining: 2m 41s\n",
            "277:\tlearn: 1.0329940\ttotal: 1m 1s\tremaining: 2m 40s\n",
            "278:\tlearn: 1.0313955\ttotal: 1m 2s\tremaining: 2m 40s\n",
            "279:\tlearn: 1.0303740\ttotal: 1m 2s\tremaining: 2m 40s\n",
            "280:\tlearn: 1.0274356\ttotal: 1m 2s\tremaining: 2m 40s\n",
            "281:\tlearn: 1.0254209\ttotal: 1m 2s\tremaining: 2m 40s\n",
            "282:\tlearn: 1.0224511\ttotal: 1m 3s\tremaining: 2m 40s\n",
            "283:\tlearn: 1.0201677\ttotal: 1m 3s\tremaining: 2m 40s\n",
            "284:\tlearn: 1.0171563\ttotal: 1m 3s\tremaining: 2m 40s\n",
            "285:\tlearn: 1.0157439\ttotal: 1m 4s\tremaining: 2m 40s\n",
            "286:\tlearn: 1.0148958\ttotal: 1m 4s\tremaining: 2m 40s\n",
            "287:\tlearn: 1.0130785\ttotal: 1m 4s\tremaining: 2m 40s\n",
            "288:\tlearn: 1.0120485\ttotal: 1m 5s\tremaining: 2m 40s\n",
            "289:\tlearn: 1.0094095\ttotal: 1m 5s\tremaining: 2m 40s\n",
            "290:\tlearn: 1.0073900\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "291:\tlearn: 1.0050743\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "292:\tlearn: 1.0022652\ttotal: 1m 6s\tremaining: 2m 40s\n",
            "293:\tlearn: 1.0004856\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "294:\tlearn: 0.9996297\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "295:\tlearn: 0.9982007\ttotal: 1m 6s\tremaining: 2m 39s\n",
            "296:\tlearn: 0.9965033\ttotal: 1m 7s\tremaining: 2m 39s\n",
            "297:\tlearn: 0.9949348\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "298:\tlearn: 0.9944643\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "299:\tlearn: 0.9911097\ttotal: 1m 7s\tremaining: 2m 38s\n",
            "300:\tlearn: 0.9899668\ttotal: 1m 7s\tremaining: 2m 37s\n",
            "301:\tlearn: 0.9887132\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "302:\tlearn: 0.9875094\ttotal: 1m 8s\tremaining: 2m 37s\n",
            "303:\tlearn: 0.9863763\ttotal: 1m 8s\tremaining: 2m 36s\n",
            "304:\tlearn: 0.9858475\ttotal: 1m 8s\tremaining: 2m 36s\n",
            "305:\tlearn: 0.9839791\ttotal: 1m 8s\tremaining: 2m 36s\n",
            "306:\tlearn: 0.9831518\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "307:\tlearn: 0.9812131\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "308:\tlearn: 0.9804360\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "309:\tlearn: 0.9798235\ttotal: 1m 9s\tremaining: 2m 35s\n",
            "310:\tlearn: 0.9777175\ttotal: 1m 9s\tremaining: 2m 34s\n",
            "311:\tlearn: 0.9763063\ttotal: 1m 10s\tremaining: 2m 34s\n",
            "312:\tlearn: 0.9728023\ttotal: 1m 10s\tremaining: 2m 34s\n",
            "313:\tlearn: 0.9707785\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "314:\tlearn: 0.9684520\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "315:\tlearn: 0.9667252\ttotal: 1m 10s\tremaining: 2m 33s\n",
            "316:\tlearn: 0.9661048\ttotal: 1m 10s\tremaining: 2m 32s\n",
            "317:\tlearn: 0.9640594\ttotal: 1m 11s\tremaining: 2m 32s\n",
            "318:\tlearn: 0.9621324\ttotal: 1m 11s\tremaining: 2m 32s\n",
            "319:\tlearn: 0.9599645\ttotal: 1m 11s\tremaining: 2m 32s\n",
            "320:\tlearn: 0.9582557\ttotal: 1m 11s\tremaining: 2m 31s\n",
            "321:\tlearn: 0.9565813\ttotal: 1m 11s\tremaining: 2m 31s\n",
            "322:\tlearn: 0.9559507\ttotal: 1m 12s\tremaining: 2m 31s\n",
            "323:\tlearn: 0.9548185\ttotal: 1m 12s\tremaining: 2m 30s\n",
            "324:\tlearn: 0.9541552\ttotal: 1m 12s\tremaining: 2m 30s\n",
            "325:\tlearn: 0.9530386\ttotal: 1m 12s\tremaining: 2m 30s\n",
            "326:\tlearn: 0.9515364\ttotal: 1m 12s\tremaining: 2m 30s\n",
            "327:\tlearn: 0.9493138\ttotal: 1m 13s\tremaining: 2m 29s\n",
            "328:\tlearn: 0.9482604\ttotal: 1m 13s\tremaining: 2m 29s\n",
            "329:\tlearn: 0.9459229\ttotal: 1m 13s\tremaining: 2m 29s\n",
            "330:\tlearn: 0.9442964\ttotal: 1m 13s\tremaining: 2m 28s\n",
            "331:\tlearn: 0.9421074\ttotal: 1m 13s\tremaining: 2m 28s\n",
            "332:\tlearn: 0.9409535\ttotal: 1m 14s\tremaining: 2m 28s\n",
            "333:\tlearn: 0.9391853\ttotal: 1m 14s\tremaining: 2m 28s\n",
            "334:\tlearn: 0.9366846\ttotal: 1m 14s\tremaining: 2m 27s\n",
            "335:\tlearn: 0.9353694\ttotal: 1m 14s\tremaining: 2m 27s\n",
            "336:\tlearn: 0.9331785\ttotal: 1m 14s\tremaining: 2m 27s\n",
            "337:\tlearn: 0.9325284\ttotal: 1m 14s\tremaining: 2m 26s\n",
            "338:\tlearn: 0.9316350\ttotal: 1m 15s\tremaining: 2m 26s\n",
            "339:\tlearn: 0.9290659\ttotal: 1m 15s\tremaining: 2m 26s\n",
            "340:\tlearn: 0.9286576\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "341:\tlearn: 0.9255108\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "342:\tlearn: 0.9242580\ttotal: 1m 15s\tremaining: 2m 25s\n",
            "343:\tlearn: 0.9212861\ttotal: 1m 16s\tremaining: 2m 25s\n",
            "344:\tlearn: 0.9191052\ttotal: 1m 16s\tremaining: 2m 25s\n",
            "345:\tlearn: 0.9183643\ttotal: 1m 16s\tremaining: 2m 25s\n",
            "346:\tlearn: 0.9179741\ttotal: 1m 17s\tremaining: 2m 25s\n",
            "347:\tlearn: 0.9171026\ttotal: 1m 17s\tremaining: 2m 25s\n",
            "348:\tlearn: 0.9166860\ttotal: 1m 17s\tremaining: 2m 25s\n",
            "349:\tlearn: 0.9151434\ttotal: 1m 18s\tremaining: 2m 25s\n",
            "350:\tlearn: 0.9145471\ttotal: 1m 18s\tremaining: 2m 25s\n",
            "351:\tlearn: 0.9137522\ttotal: 1m 19s\tremaining: 2m 25s\n",
            "352:\tlearn: 0.9124726\ttotal: 1m 19s\tremaining: 2m 25s\n",
            "353:\tlearn: 0.9108822\ttotal: 1m 19s\tremaining: 2m 25s\n",
            "354:\tlearn: 0.9088109\ttotal: 1m 20s\tremaining: 2m 25s\n",
            "355:\tlearn: 0.9082656\ttotal: 1m 20s\tremaining: 2m 25s\n",
            "356:\tlearn: 0.9068634\ttotal: 1m 20s\tremaining: 2m 25s\n",
            "357:\tlearn: 0.9046987\ttotal: 1m 21s\tremaining: 2m 25s\n",
            "358:\tlearn: 0.9027691\ttotal: 1m 21s\tremaining: 2m 25s\n",
            "359:\tlearn: 0.9011445\ttotal: 1m 21s\tremaining: 2m 25s\n",
            "360:\tlearn: 0.9005082\ttotal: 1m 22s\tremaining: 2m 25s\n",
            "361:\tlearn: 0.8999807\ttotal: 1m 22s\tremaining: 2m 25s\n",
            "362:\tlearn: 0.8974138\ttotal: 1m 23s\tremaining: 2m 25s\n",
            "363:\tlearn: 0.8961034\ttotal: 1m 23s\tremaining: 2m 25s\n",
            "364:\tlearn: 0.8945100\ttotal: 1m 23s\tremaining: 2m 25s\n",
            "365:\tlearn: 0.8929185\ttotal: 1m 23s\tremaining: 2m 24s\n",
            "366:\tlearn: 0.8914157\ttotal: 1m 23s\tremaining: 2m 24s\n",
            "367:\tlearn: 0.8893585\ttotal: 1m 23s\tremaining: 2m 24s\n",
            "368:\tlearn: 0.8884034\ttotal: 1m 24s\tremaining: 2m 23s\n",
            "369:\tlearn: 0.8878129\ttotal: 1m 24s\tremaining: 2m 23s\n",
            "370:\tlearn: 0.8864848\ttotal: 1m 24s\tremaining: 2m 23s\n",
            "371:\tlearn: 0.8843410\ttotal: 1m 24s\tremaining: 2m 23s\n",
            "372:\tlearn: 0.8826347\ttotal: 1m 24s\tremaining: 2m 22s\n",
            "373:\tlearn: 0.8812389\ttotal: 1m 25s\tremaining: 2m 22s\n",
            "374:\tlearn: 0.8795730\ttotal: 1m 25s\tremaining: 2m 22s\n",
            "375:\tlearn: 0.8789293\ttotal: 1m 25s\tremaining: 2m 21s\n",
            "376:\tlearn: 0.8780253\ttotal: 1m 25s\tremaining: 2m 21s\n",
            "377:\tlearn: 0.8762938\ttotal: 1m 25s\tremaining: 2m 21s\n",
            "378:\tlearn: 0.8756205\ttotal: 1m 26s\tremaining: 2m 21s\n",
            "379:\tlearn: 0.8739087\ttotal: 1m 26s\tremaining: 2m 20s\n",
            "380:\tlearn: 0.8721457\ttotal: 1m 26s\tremaining: 2m 20s\n",
            "381:\tlearn: 0.8696322\ttotal: 1m 26s\tremaining: 2m 20s\n",
            "382:\tlearn: 0.8686466\ttotal: 1m 26s\tremaining: 2m 19s\n",
            "383:\tlearn: 0.8681134\ttotal: 1m 26s\tremaining: 2m 19s\n",
            "384:\tlearn: 0.8676267\ttotal: 1m 27s\tremaining: 2m 19s\n",
            "385:\tlearn: 0.8668232\ttotal: 1m 27s\tremaining: 2m 18s\n",
            "386:\tlearn: 0.8663429\ttotal: 1m 27s\tremaining: 2m 18s\n",
            "387:\tlearn: 0.8653878\ttotal: 1m 27s\tremaining: 2m 18s\n",
            "388:\tlearn: 0.8646207\ttotal: 1m 27s\tremaining: 2m 18s\n",
            "389:\tlearn: 0.8633256\ttotal: 1m 28s\tremaining: 2m 17s\n",
            "390:\tlearn: 0.8625204\ttotal: 1m 28s\tremaining: 2m 17s\n",
            "391:\tlearn: 0.8609498\ttotal: 1m 28s\tremaining: 2m 17s\n",
            "392:\tlearn: 0.8600079\ttotal: 1m 28s\tremaining: 2m 16s\n",
            "393:\tlearn: 0.8589362\ttotal: 1m 28s\tremaining: 2m 16s\n",
            "394:\tlearn: 0.8580352\ttotal: 1m 29s\tremaining: 2m 16s\n",
            "395:\tlearn: 0.8560485\ttotal: 1m 29s\tremaining: 2m 16s\n",
            "396:\tlearn: 0.8538188\ttotal: 1m 29s\tremaining: 2m 15s\n",
            "397:\tlearn: 0.8530207\ttotal: 1m 29s\tremaining: 2m 15s\n",
            "398:\tlearn: 0.8518681\ttotal: 1m 29s\tremaining: 2m 15s\n",
            "399:\tlearn: 0.8503673\ttotal: 1m 30s\tremaining: 2m 15s\n",
            "400:\tlearn: 0.8493204\ttotal: 1m 30s\tremaining: 2m 15s\n",
            "401:\tlearn: 0.8479966\ttotal: 1m 30s\tremaining: 2m 15s\n",
            "402:\tlearn: 0.8462633\ttotal: 1m 31s\tremaining: 2m 15s\n",
            "403:\tlearn: 0.8459659\ttotal: 1m 31s\tremaining: 2m 15s\n",
            "404:\tlearn: 0.8455159\ttotal: 1m 31s\tremaining: 2m 15s\n",
            "405:\tlearn: 0.8449348\ttotal: 1m 32s\tremaining: 2m 15s\n",
            "406:\tlearn: 0.8447062\ttotal: 1m 32s\tremaining: 2m 15s\n",
            "407:\tlearn: 0.8437714\ttotal: 1m 33s\tremaining: 2m 15s\n",
            "408:\tlearn: 0.8426498\ttotal: 1m 33s\tremaining: 2m 14s\n",
            "409:\tlearn: 0.8415988\ttotal: 1m 33s\tremaining: 2m 14s\n",
            "410:\tlearn: 0.8408498\ttotal: 1m 33s\tremaining: 2m 14s\n",
            "411:\tlearn: 0.8393093\ttotal: 1m 33s\tremaining: 2m 14s\n",
            "412:\tlearn: 0.8384897\ttotal: 1m 34s\tremaining: 2m 13s\n",
            "413:\tlearn: 0.8371577\ttotal: 1m 34s\tremaining: 2m 13s\n",
            "414:\tlearn: 0.8363627\ttotal: 1m 34s\tremaining: 2m 13s\n",
            "415:\tlearn: 0.8340011\ttotal: 1m 34s\tremaining: 2m 13s\n",
            "416:\tlearn: 0.8334067\ttotal: 1m 34s\tremaining: 2m 12s\n",
            "417:\tlearn: 0.8330228\ttotal: 1m 35s\tremaining: 2m 12s\n",
            "418:\tlearn: 0.8314621\ttotal: 1m 35s\tremaining: 2m 12s\n",
            "419:\tlearn: 0.8310343\ttotal: 1m 35s\tremaining: 2m 11s\n",
            "420:\tlearn: 0.8289983\ttotal: 1m 35s\tremaining: 2m 11s\n",
            "421:\tlearn: 0.8283458\ttotal: 1m 35s\tremaining: 2m 11s\n",
            "422:\tlearn: 0.8279913\ttotal: 1m 36s\tremaining: 2m 11s\n",
            "423:\tlearn: 0.8275071\ttotal: 1m 36s\tremaining: 2m 10s\n",
            "424:\tlearn: 0.8262421\ttotal: 1m 36s\tremaining: 2m 10s\n",
            "425:\tlearn: 0.8257038\ttotal: 1m 36s\tremaining: 2m 10s\n",
            "426:\tlearn: 0.8240780\ttotal: 1m 36s\tremaining: 2m 9s\n",
            "427:\tlearn: 0.8233716\ttotal: 1m 37s\tremaining: 2m 9s\n",
            "428:\tlearn: 0.8229661\ttotal: 1m 37s\tremaining: 2m 9s\n",
            "429:\tlearn: 0.8211818\ttotal: 1m 37s\tremaining: 2m 9s\n",
            "430:\tlearn: 0.8209440\ttotal: 1m 37s\tremaining: 2m 8s\n",
            "431:\tlearn: 0.8193368\ttotal: 1m 37s\tremaining: 2m 8s\n",
            "432:\tlearn: 0.8184416\ttotal: 1m 37s\tremaining: 2m 8s\n",
            "433:\tlearn: 0.8181492\ttotal: 1m 38s\tremaining: 2m 8s\n",
            "434:\tlearn: 0.8179369\ttotal: 1m 38s\tremaining: 2m 7s\n",
            "435:\tlearn: 0.8162615\ttotal: 1m 38s\tremaining: 2m 7s\n",
            "436:\tlearn: 0.8148183\ttotal: 1m 38s\tremaining: 2m 7s\n",
            "437:\tlearn: 0.8132342\ttotal: 1m 38s\tremaining: 2m 6s\n",
            "438:\tlearn: 0.8129517\ttotal: 1m 39s\tremaining: 2m 6s\n",
            "439:\tlearn: 0.8116718\ttotal: 1m 39s\tremaining: 2m 6s\n",
            "440:\tlearn: 0.8111445\ttotal: 1m 39s\tremaining: 2m 6s\n",
            "441:\tlearn: 0.8108321\ttotal: 1m 39s\tremaining: 2m 5s\n",
            "442:\tlearn: 0.8102684\ttotal: 1m 39s\tremaining: 2m 5s\n",
            "443:\tlearn: 0.8090631\ttotal: 1m 40s\tremaining: 2m 5s\n",
            "444:\tlearn: 0.8077131\ttotal: 1m 40s\tremaining: 2m 5s\n",
            "445:\tlearn: 0.8069240\ttotal: 1m 40s\tremaining: 2m 4s\n",
            "446:\tlearn: 0.8052733\ttotal: 1m 40s\tremaining: 2m 4s\n",
            "447:\tlearn: 0.8049782\ttotal: 1m 40s\tremaining: 2m 4s\n",
            "448:\tlearn: 0.8034604\ttotal: 1m 41s\tremaining: 2m 3s\n",
            "449:\tlearn: 0.8026475\ttotal: 1m 41s\tremaining: 2m 3s\n",
            "450:\tlearn: 0.8024199\ttotal: 1m 41s\tremaining: 2m 3s\n",
            "451:\tlearn: 0.8020207\ttotal: 1m 41s\tremaining: 2m 3s\n",
            "452:\tlearn: 0.8009602\ttotal: 1m 41s\tremaining: 2m 2s\n",
            "453:\tlearn: 0.7993137\ttotal: 1m 41s\tremaining: 2m 2s\n",
            "454:\tlearn: 0.7989273\ttotal: 1m 42s\tremaining: 2m 2s\n",
            "455:\tlearn: 0.7985136\ttotal: 1m 42s\tremaining: 2m 2s\n",
            "456:\tlearn: 0.7975496\ttotal: 1m 42s\tremaining: 2m 1s\n",
            "457:\tlearn: 0.7961641\ttotal: 1m 42s\tremaining: 2m 1s\n",
            "458:\tlearn: 0.7946286\ttotal: 1m 42s\tremaining: 2m 1s\n",
            "459:\tlearn: 0.7937198\ttotal: 1m 43s\tremaining: 2m 1s\n",
            "460:\tlearn: 0.7933170\ttotal: 1m 43s\tremaining: 2m\n",
            "461:\tlearn: 0.7930343\ttotal: 1m 43s\tremaining: 2m\n",
            "462:\tlearn: 0.7927318\ttotal: 1m 44s\tremaining: 2m\n",
            "463:\tlearn: 0.7916101\ttotal: 1m 44s\tremaining: 2m\n",
            "464:\tlearn: 0.7910228\ttotal: 1m 44s\tremaining: 2m\n",
            "465:\tlearn: 0.7896571\ttotal: 1m 45s\tremaining: 2m\n",
            "466:\tlearn: 0.7883295\ttotal: 1m 45s\tremaining: 2m\n",
            "467:\tlearn: 0.7879950\ttotal: 1m 45s\tremaining: 2m\n",
            "468:\tlearn: 0.7876056\ttotal: 1m 46s\tremaining: 2m\n",
            "469:\tlearn: 0.7859244\ttotal: 1m 46s\tremaining: 2m\n",
            "470:\tlearn: 0.7856359\ttotal: 1m 46s\tremaining: 1m 59s\n",
            "471:\tlearn: 0.7852517\ttotal: 1m 47s\tremaining: 1m 59s\n",
            "472:\tlearn: 0.7848626\ttotal: 1m 47s\tremaining: 1m 59s\n",
            "473:\tlearn: 0.7837177\ttotal: 1m 47s\tremaining: 1m 59s\n",
            "474:\tlearn: 0.7825229\ttotal: 1m 47s\tremaining: 1m 59s\n",
            "475:\tlearn: 0.7808347\ttotal: 1m 47s\tremaining: 1m 58s\n",
            "476:\tlearn: 0.7795456\ttotal: 1m 48s\tremaining: 1m 58s\n",
            "477:\tlearn: 0.7787884\ttotal: 1m 48s\tremaining: 1m 58s\n",
            "478:\tlearn: 0.7780158\ttotal: 1m 48s\tremaining: 1m 57s\n",
            "479:\tlearn: 0.7763246\ttotal: 1m 48s\tremaining: 1m 57s\n",
            "480:\tlearn: 0.7749765\ttotal: 1m 48s\tremaining: 1m 57s\n",
            "481:\tlearn: 0.7735841\ttotal: 1m 49s\tremaining: 1m 57s\n",
            "482:\tlearn: 0.7732536\ttotal: 1m 49s\tremaining: 1m 56s\n",
            "483:\tlearn: 0.7722982\ttotal: 1m 49s\tremaining: 1m 56s\n",
            "484:\tlearn: 0.7708362\ttotal: 1m 49s\tremaining: 1m 56s\n",
            "485:\tlearn: 0.7700875\ttotal: 1m 49s\tremaining: 1m 56s\n",
            "486:\tlearn: 0.7687837\ttotal: 1m 50s\tremaining: 1m 55s\n",
            "487:\tlearn: 0.7679957\ttotal: 1m 50s\tremaining: 1m 55s\n",
            "488:\tlearn: 0.7668994\ttotal: 1m 50s\tremaining: 1m 55s\n",
            "489:\tlearn: 0.7660459\ttotal: 1m 50s\tremaining: 1m 55s\n",
            "490:\tlearn: 0.7642977\ttotal: 1m 50s\tremaining: 1m 54s\n",
            "491:\tlearn: 0.7628799\ttotal: 1m 51s\tremaining: 1m 54s\n",
            "492:\tlearn: 0.7624730\ttotal: 1m 51s\tremaining: 1m 54s\n",
            "493:\tlearn: 0.7611563\ttotal: 1m 51s\tremaining: 1m 54s\n",
            "494:\tlearn: 0.7604453\ttotal: 1m 51s\tremaining: 1m 53s\n",
            "495:\tlearn: 0.7598553\ttotal: 1m 51s\tremaining: 1m 53s\n",
            "496:\tlearn: 0.7585775\ttotal: 1m 51s\tremaining: 1m 53s\n",
            "497:\tlearn: 0.7573796\ttotal: 1m 52s\tremaining: 1m 53s\n",
            "498:\tlearn: 0.7571256\ttotal: 1m 52s\tremaining: 1m 52s\n",
            "499:\tlearn: 0.7560672\ttotal: 1m 52s\tremaining: 1m 52s\n",
            "500:\tlearn: 0.7556025\ttotal: 1m 52s\tremaining: 1m 52s\n",
            "501:\tlearn: 0.7544599\ttotal: 1m 52s\tremaining: 1m 52s\n",
            "502:\tlearn: 0.7538854\ttotal: 1m 53s\tremaining: 1m 51s\n",
            "503:\tlearn: 0.7531429\ttotal: 1m 53s\tremaining: 1m 51s\n",
            "504:\tlearn: 0.7522990\ttotal: 1m 53s\tremaining: 1m 51s\n",
            "505:\tlearn: 0.7516425\ttotal: 1m 53s\tremaining: 1m 50s\n",
            "506:\tlearn: 0.7508897\ttotal: 1m 53s\tremaining: 1m 50s\n",
            "507:\tlearn: 0.7503617\ttotal: 1m 54s\tremaining: 1m 50s\n",
            "508:\tlearn: 0.7493986\ttotal: 1m 54s\tremaining: 1m 50s\n",
            "509:\tlearn: 0.7484368\ttotal: 1m 54s\tremaining: 1m 49s\n",
            "510:\tlearn: 0.7474755\ttotal: 1m 54s\tremaining: 1m 49s\n",
            "511:\tlearn: 0.7460174\ttotal: 1m 54s\tremaining: 1m 49s\n",
            "512:\tlearn: 0.7447423\ttotal: 1m 55s\tremaining: 1m 49s\n",
            "513:\tlearn: 0.7436145\ttotal: 1m 55s\tremaining: 1m 48s\n",
            "514:\tlearn: 0.7421213\ttotal: 1m 55s\tremaining: 1m 48s\n",
            "515:\tlearn: 0.7409172\ttotal: 1m 55s\tremaining: 1m 48s\n",
            "516:\tlearn: 0.7397054\ttotal: 1m 55s\tremaining: 1m 48s\n",
            "517:\tlearn: 0.7393220\ttotal: 1m 55s\tremaining: 1m 47s\n",
            "518:\tlearn: 0.7380944\ttotal: 1m 56s\tremaining: 1m 47s\n",
            "519:\tlearn: 0.7376598\ttotal: 1m 56s\tremaining: 1m 47s\n",
            "520:\tlearn: 0.7369228\ttotal: 1m 56s\tremaining: 1m 47s\n",
            "521:\tlearn: 0.7366862\ttotal: 1m 56s\tremaining: 1m 46s\n",
            "522:\tlearn: 0.7361902\ttotal: 1m 56s\tremaining: 1m 46s\n",
            "523:\tlearn: 0.7359813\ttotal: 1m 57s\tremaining: 1m 46s\n",
            "524:\tlearn: 0.7356243\ttotal: 1m 57s\tremaining: 1m 46s\n",
            "525:\tlearn: 0.7349950\ttotal: 1m 57s\tremaining: 1m 46s\n",
            "526:\tlearn: 0.7346450\ttotal: 1m 58s\tremaining: 1m 46s\n",
            "527:\tlearn: 0.7334547\ttotal: 1m 58s\tremaining: 1m 46s\n",
            "528:\tlearn: 0.7325752\ttotal: 1m 58s\tremaining: 1m 45s\n",
            "529:\tlearn: 0.7317909\ttotal: 1m 59s\tremaining: 1m 45s\n",
            "530:\tlearn: 0.7309488\ttotal: 1m 59s\tremaining: 1m 45s\n",
            "531:\tlearn: 0.7304917\ttotal: 2m\tremaining: 1m 45s\n",
            "532:\tlearn: 0.7294678\ttotal: 2m\tremaining: 1m 45s\n",
            "533:\tlearn: 0.7289425\ttotal: 2m\tremaining: 1m 45s\n",
            "534:\tlearn: 0.7285905\ttotal: 2m\tremaining: 1m 45s\n",
            "535:\tlearn: 0.7279659\ttotal: 2m 1s\tremaining: 1m 44s\n",
            "536:\tlearn: 0.7277015\ttotal: 2m 1s\tremaining: 1m 44s\n",
            "537:\tlearn: 0.7266376\ttotal: 2m 1s\tremaining: 1m 44s\n",
            "538:\tlearn: 0.7263870\ttotal: 2m 1s\tremaining: 1m 44s\n",
            "539:\tlearn: 0.7256029\ttotal: 2m 1s\tremaining: 1m 43s\n",
            "540:\tlearn: 0.7250040\ttotal: 2m 2s\tremaining: 1m 43s\n",
            "541:\tlearn: 0.7244083\ttotal: 2m 2s\tremaining: 1m 43s\n",
            "542:\tlearn: 0.7240729\ttotal: 2m 2s\tremaining: 1m 43s\n",
            "543:\tlearn: 0.7237344\ttotal: 2m 2s\tremaining: 1m 42s\n",
            "544:\tlearn: 0.7233181\ttotal: 2m 2s\tremaining: 1m 42s\n",
            "545:\tlearn: 0.7220749\ttotal: 2m 2s\tremaining: 1m 42s\n",
            "546:\tlearn: 0.7217343\ttotal: 2m 3s\tremaining: 1m 41s\n",
            "547:\tlearn: 0.7211354\ttotal: 2m 3s\tremaining: 1m 41s\n",
            "548:\tlearn: 0.7197797\ttotal: 2m 3s\tremaining: 1m 41s\n",
            "549:\tlearn: 0.7187598\ttotal: 2m 3s\tremaining: 1m 41s\n",
            "550:\tlearn: 0.7176930\ttotal: 2m 3s\tremaining: 1m 41s\n",
            "551:\tlearn: 0.7166804\ttotal: 2m 4s\tremaining: 1m 40s\n",
            "552:\tlearn: 0.7164355\ttotal: 2m 4s\tremaining: 1m 40s\n",
            "553:\tlearn: 0.7160671\ttotal: 2m 4s\tremaining: 1m 40s\n",
            "554:\tlearn: 0.7157435\ttotal: 2m 4s\tremaining: 1m 40s\n",
            "555:\tlearn: 0.7155327\ttotal: 2m 4s\tremaining: 1m 39s\n",
            "556:\tlearn: 0.7144356\ttotal: 2m 5s\tremaining: 1m 39s\n",
            "557:\tlearn: 0.7135196\ttotal: 2m 5s\tremaining: 1m 39s\n",
            "558:\tlearn: 0.7130025\ttotal: 2m 5s\tremaining: 1m 39s\n",
            "559:\tlearn: 0.7124479\ttotal: 2m 5s\tremaining: 1m 38s\n",
            "560:\tlearn: 0.7116229\ttotal: 2m 5s\tremaining: 1m 38s\n",
            "561:\tlearn: 0.7106144\ttotal: 2m 6s\tremaining: 1m 38s\n",
            "562:\tlearn: 0.7104269\ttotal: 2m 6s\tremaining: 1m 37s\n",
            "563:\tlearn: 0.7100386\ttotal: 2m 6s\tremaining: 1m 37s\n",
            "564:\tlearn: 0.7092274\ttotal: 2m 6s\tremaining: 1m 37s\n",
            "565:\tlearn: 0.7084936\ttotal: 2m 6s\tremaining: 1m 37s\n",
            "566:\tlearn: 0.7079601\ttotal: 2m 7s\tremaining: 1m 36s\n",
            "567:\tlearn: 0.7076213\ttotal: 2m 7s\tremaining: 1m 36s\n",
            "568:\tlearn: 0.7071881\ttotal: 2m 7s\tremaining: 1m 36s\n",
            "569:\tlearn: 0.7068003\ttotal: 2m 7s\tremaining: 1m 36s\n",
            "570:\tlearn: 0.7057570\ttotal: 2m 7s\tremaining: 1m 36s\n",
            "571:\tlearn: 0.7055279\ttotal: 2m 7s\tremaining: 1m 35s\n",
            "572:\tlearn: 0.7049825\ttotal: 2m 8s\tremaining: 1m 35s\n",
            "573:\tlearn: 0.7041429\ttotal: 2m 8s\tremaining: 1m 35s\n",
            "574:\tlearn: 0.7036651\ttotal: 2m 8s\tremaining: 1m 35s\n",
            "575:\tlearn: 0.7034930\ttotal: 2m 8s\tremaining: 1m 34s\n",
            "576:\tlearn: 0.7031517\ttotal: 2m 8s\tremaining: 1m 34s\n",
            "577:\tlearn: 0.7022490\ttotal: 2m 9s\tremaining: 1m 34s\n",
            "578:\tlearn: 0.7020260\ttotal: 2m 9s\tremaining: 1m 34s\n",
            "579:\tlearn: 0.7011459\ttotal: 2m 9s\tremaining: 1m 33s\n",
            "580:\tlearn: 0.7004758\ttotal: 2m 9s\tremaining: 1m 33s\n",
            "581:\tlearn: 0.7000400\ttotal: 2m 9s\tremaining: 1m 33s\n",
            "582:\tlearn: 0.6997932\ttotal: 2m 10s\tremaining: 1m 33s\n",
            "583:\tlearn: 0.6990944\ttotal: 2m 10s\tremaining: 1m 32s\n",
            "584:\tlearn: 0.6980554\ttotal: 2m 10s\tremaining: 1m 32s\n",
            "585:\tlearn: 0.6978400\ttotal: 2m 10s\tremaining: 1m 32s\n",
            "586:\tlearn: 0.6970326\ttotal: 2m 10s\tremaining: 1m 32s\n",
            "587:\tlearn: 0.6963217\ttotal: 2m 11s\tremaining: 1m 31s\n",
            "588:\tlearn: 0.6959657\ttotal: 2m 11s\tremaining: 1m 31s\n",
            "589:\tlearn: 0.6948420\ttotal: 2m 12s\tremaining: 1m 31s\n",
            "590:\tlearn: 0.6939700\ttotal: 2m 12s\tremaining: 1m 31s\n",
            "591:\tlearn: 0.6931956\ttotal: 2m 12s\tremaining: 1m 31s\n",
            "592:\tlearn: 0.6923664\ttotal: 2m 13s\tremaining: 1m 31s\n",
            "593:\tlearn: 0.6920619\ttotal: 2m 13s\tremaining: 1m 31s\n",
            "594:\tlearn: 0.6911532\ttotal: 2m 13s\tremaining: 1m 31s\n",
            "595:\tlearn: 0.6902563\ttotal: 2m 14s\tremaining: 1m 30s\n",
            "596:\tlearn: 0.6894606\ttotal: 2m 14s\tremaining: 1m 30s\n",
            "597:\tlearn: 0.6892509\ttotal: 2m 14s\tremaining: 1m 30s\n",
            "598:\tlearn: 0.6889635\ttotal: 2m 14s\tremaining: 1m 30s\n",
            "599:\tlearn: 0.6885523\ttotal: 2m 15s\tremaining: 1m 30s\n",
            "600:\tlearn: 0.6882272\ttotal: 2m 15s\tremaining: 1m 29s\n",
            "601:\tlearn: 0.6877048\ttotal: 2m 15s\tremaining: 1m 29s\n",
            "602:\tlearn: 0.6872459\ttotal: 2m 15s\tremaining: 1m 29s\n",
            "603:\tlearn: 0.6868832\ttotal: 2m 15s\tremaining: 1m 29s\n",
            "604:\tlearn: 0.6861986\ttotal: 2m 15s\tremaining: 1m 28s\n",
            "605:\tlearn: 0.6855919\ttotal: 2m 16s\tremaining: 1m 28s\n",
            "606:\tlearn: 0.6853651\ttotal: 2m 16s\tremaining: 1m 28s\n",
            "607:\tlearn: 0.6851007\ttotal: 2m 16s\tremaining: 1m 28s\n",
            "608:\tlearn: 0.6841441\ttotal: 2m 16s\tremaining: 1m 27s\n",
            "609:\tlearn: 0.6834822\ttotal: 2m 16s\tremaining: 1m 27s\n",
            "610:\tlearn: 0.6828622\ttotal: 2m 17s\tremaining: 1m 27s\n",
            "611:\tlearn: 0.6821785\ttotal: 2m 17s\tremaining: 1m 27s\n",
            "612:\tlearn: 0.6815655\ttotal: 2m 17s\tremaining: 1m 26s\n",
            "613:\tlearn: 0.6803294\ttotal: 2m 17s\tremaining: 1m 26s\n",
            "614:\tlearn: 0.6800043\ttotal: 2m 17s\tremaining: 1m 26s\n",
            "615:\tlearn: 0.6794898\ttotal: 2m 18s\tremaining: 1m 26s\n",
            "616:\tlearn: 0.6785900\ttotal: 2m 18s\tremaining: 1m 25s\n",
            "617:\tlearn: 0.6783715\ttotal: 2m 18s\tremaining: 1m 25s\n",
            "618:\tlearn: 0.6781647\ttotal: 2m 18s\tremaining: 1m 25s\n",
            "619:\tlearn: 0.6778250\ttotal: 2m 18s\tremaining: 1m 25s\n",
            "620:\tlearn: 0.6771734\ttotal: 2m 19s\tremaining: 1m 24s\n",
            "621:\tlearn: 0.6768587\ttotal: 2m 19s\tremaining: 1m 24s\n",
            "622:\tlearn: 0.6765090\ttotal: 2m 19s\tremaining: 1m 24s\n",
            "623:\tlearn: 0.6757695\ttotal: 2m 19s\tremaining: 1m 24s\n",
            "624:\tlearn: 0.6748522\ttotal: 2m 19s\tremaining: 1m 23s\n",
            "625:\tlearn: 0.6745604\ttotal: 2m 20s\tremaining: 1m 23s\n",
            "626:\tlearn: 0.6743491\ttotal: 2m 20s\tremaining: 1m 23s\n",
            "627:\tlearn: 0.6738427\ttotal: 2m 20s\tremaining: 1m 23s\n",
            "628:\tlearn: 0.6731129\ttotal: 2m 20s\tremaining: 1m 22s\n",
            "629:\tlearn: 0.6723560\ttotal: 2m 20s\tremaining: 1m 22s\n",
            "630:\tlearn: 0.6722241\ttotal: 2m 20s\tremaining: 1m 22s\n",
            "631:\tlearn: 0.6719341\ttotal: 2m 21s\tremaining: 1m 22s\n",
            "632:\tlearn: 0.6714697\ttotal: 2m 21s\tremaining: 1m 21s\n",
            "633:\tlearn: 0.6711978\ttotal: 2m 21s\tremaining: 1m 21s\n",
            "634:\tlearn: 0.6707814\ttotal: 2m 21s\tremaining: 1m 21s\n",
            "635:\tlearn: 0.6695636\ttotal: 2m 21s\tremaining: 1m 21s\n",
            "636:\tlearn: 0.6684711\ttotal: 2m 22s\tremaining: 1m 21s\n",
            "637:\tlearn: 0.6682925\ttotal: 2m 22s\tremaining: 1m 20s\n",
            "638:\tlearn: 0.6681167\ttotal: 2m 22s\tremaining: 1m 20s\n",
            "639:\tlearn: 0.6674192\ttotal: 2m 22s\tremaining: 1m 20s\n",
            "640:\tlearn: 0.6667989\ttotal: 2m 22s\tremaining: 1m 20s\n",
            "641:\tlearn: 0.6660562\ttotal: 2m 23s\tremaining: 1m 19s\n",
            "642:\tlearn: 0.6655443\ttotal: 2m 23s\tremaining: 1m 19s\n",
            "643:\tlearn: 0.6648913\ttotal: 2m 23s\tremaining: 1m 19s\n",
            "644:\tlearn: 0.6639518\ttotal: 2m 23s\tremaining: 1m 19s\n",
            "645:\tlearn: 0.6633250\ttotal: 2m 23s\tremaining: 1m 18s\n",
            "646:\tlearn: 0.6625895\ttotal: 2m 24s\tremaining: 1m 18s\n",
            "647:\tlearn: 0.6622340\ttotal: 2m 24s\tremaining: 1m 18s\n",
            "648:\tlearn: 0.6617352\ttotal: 2m 24s\tremaining: 1m 18s\n",
            "649:\tlearn: 0.6610464\ttotal: 2m 24s\tremaining: 1m 18s\n",
            "650:\tlearn: 0.6607183\ttotal: 2m 25s\tremaining: 1m 17s\n",
            "651:\tlearn: 0.6604845\ttotal: 2m 25s\tremaining: 1m 17s\n",
            "652:\tlearn: 0.6597279\ttotal: 2m 26s\tremaining: 1m 17s\n",
            "653:\tlearn: 0.6595102\ttotal: 2m 26s\tremaining: 1m 17s\n",
            "654:\tlearn: 0.6590701\ttotal: 2m 26s\tremaining: 1m 17s\n",
            "655:\tlearn: 0.6589758\ttotal: 2m 27s\tremaining: 1m 17s\n",
            "656:\tlearn: 0.6587151\ttotal: 2m 27s\tremaining: 1m 17s\n",
            "657:\tlearn: 0.6583943\ttotal: 2m 27s\tremaining: 1m 16s\n",
            "658:\tlearn: 0.6581401\ttotal: 2m 28s\tremaining: 1m 16s\n",
            "659:\tlearn: 0.6578121\ttotal: 2m 28s\tremaining: 1m 16s\n",
            "660:\tlearn: 0.6569418\ttotal: 2m 28s\tremaining: 1m 16s\n",
            "661:\tlearn: 0.6567700\ttotal: 2m 28s\tremaining: 1m 15s\n",
            "662:\tlearn: 0.6560167\ttotal: 2m 28s\tremaining: 1m 15s\n",
            "663:\tlearn: 0.6551017\ttotal: 2m 28s\tremaining: 1m 15s\n",
            "664:\tlearn: 0.6549917\ttotal: 2m 29s\tremaining: 1m 15s\n",
            "665:\tlearn: 0.6548943\ttotal: 2m 29s\tremaining: 1m 14s\n",
            "666:\tlearn: 0.6542134\ttotal: 2m 29s\tremaining: 1m 14s\n",
            "667:\tlearn: 0.6536312\ttotal: 2m 29s\tremaining: 1m 14s\n",
            "668:\tlearn: 0.6535220\ttotal: 2m 29s\tremaining: 1m 14s\n",
            "669:\tlearn: 0.6528663\ttotal: 2m 30s\tremaining: 1m 13s\n",
            "670:\tlearn: 0.6524555\ttotal: 2m 30s\tremaining: 1m 13s\n",
            "671:\tlearn: 0.6518044\ttotal: 2m 30s\tremaining: 1m 13s\n",
            "672:\tlearn: 0.6512311\ttotal: 2m 30s\tremaining: 1m 13s\n",
            "673:\tlearn: 0.6510250\ttotal: 2m 30s\tremaining: 1m 12s\n",
            "674:\tlearn: 0.6509257\ttotal: 2m 31s\tremaining: 1m 12s\n",
            "675:\tlearn: 0.6508138\ttotal: 2m 31s\tremaining: 1m 12s\n",
            "676:\tlearn: 0.6504757\ttotal: 2m 31s\tremaining: 1m 12s\n",
            "677:\tlearn: 0.6497327\ttotal: 2m 31s\tremaining: 1m 12s\n",
            "678:\tlearn: 0.6495317\ttotal: 2m 31s\tremaining: 1m 11s\n",
            "679:\tlearn: 0.6491689\ttotal: 2m 32s\tremaining: 1m 11s\n",
            "680:\tlearn: 0.6485860\ttotal: 2m 32s\tremaining: 1m 11s\n",
            "681:\tlearn: 0.6480684\ttotal: 2m 32s\tremaining: 1m 11s\n",
            "682:\tlearn: 0.6479096\ttotal: 2m 32s\tremaining: 1m 10s\n",
            "683:\tlearn: 0.6477416\ttotal: 2m 32s\tremaining: 1m 10s\n",
            "684:\tlearn: 0.6475540\ttotal: 2m 33s\tremaining: 1m 10s\n",
            "685:\tlearn: 0.6470010\ttotal: 2m 33s\tremaining: 1m 10s\n",
            "686:\tlearn: 0.6464306\ttotal: 2m 33s\tremaining: 1m 9s\n",
            "687:\tlearn: 0.6459146\ttotal: 2m 33s\tremaining: 1m 9s\n",
            "688:\tlearn: 0.6458255\ttotal: 2m 33s\tremaining: 1m 9s\n",
            "689:\tlearn: 0.6456127\ttotal: 2m 33s\tremaining: 1m 9s\n",
            "690:\tlearn: 0.6454403\ttotal: 2m 34s\tremaining: 1m 8s\n",
            "691:\tlearn: 0.6446522\ttotal: 2m 34s\tremaining: 1m 8s\n",
            "692:\tlearn: 0.6438790\ttotal: 2m 34s\tremaining: 1m 8s\n",
            "693:\tlearn: 0.6433028\ttotal: 2m 34s\tremaining: 1m 8s\n",
            "694:\tlearn: 0.6430348\ttotal: 2m 34s\tremaining: 1m 7s\n",
            "695:\tlearn: 0.6423118\ttotal: 2m 35s\tremaining: 1m 7s\n",
            "696:\tlearn: 0.6422104\ttotal: 2m 35s\tremaining: 1m 7s\n",
            "697:\tlearn: 0.6420111\ttotal: 2m 35s\tremaining: 1m 7s\n",
            "698:\tlearn: 0.6416880\ttotal: 2m 35s\tremaining: 1m 7s\n",
            "699:\tlearn: 0.6415291\ttotal: 2m 35s\tremaining: 1m 6s\n",
            "700:\tlearn: 0.6414378\ttotal: 2m 36s\tremaining: 1m 6s\n",
            "701:\tlearn: 0.6408279\ttotal: 2m 36s\tremaining: 1m 6s\n",
            "702:\tlearn: 0.6405240\ttotal: 2m 36s\tremaining: 1m 6s\n",
            "703:\tlearn: 0.6404403\ttotal: 2m 36s\tremaining: 1m 5s\n",
            "704:\tlearn: 0.6399024\ttotal: 2m 36s\tremaining: 1m 5s\n",
            "705:\tlearn: 0.6397383\ttotal: 2m 37s\tremaining: 1m 5s\n",
            "706:\tlearn: 0.6396032\ttotal: 2m 37s\tremaining: 1m 5s\n",
            "707:\tlearn: 0.6395177\ttotal: 2m 37s\tremaining: 1m 4s\n",
            "708:\tlearn: 0.6391427\ttotal: 2m 37s\tremaining: 1m 4s\n",
            "709:\tlearn: 0.6389738\ttotal: 2m 37s\tremaining: 1m 4s\n",
            "710:\tlearn: 0.6388901\ttotal: 2m 38s\tremaining: 1m 4s\n",
            "711:\tlearn: 0.6385962\ttotal: 2m 38s\tremaining: 1m 4s\n",
            "712:\tlearn: 0.6382126\ttotal: 2m 38s\tremaining: 1m 3s\n",
            "713:\tlearn: 0.6375819\ttotal: 2m 39s\tremaining: 1m 3s\n",
            "714:\tlearn: 0.6370027\ttotal: 2m 39s\tremaining: 1m 3s\n",
            "715:\tlearn: 0.6363890\ttotal: 2m 39s\tremaining: 1m 3s\n",
            "716:\tlearn: 0.6360606\ttotal: 2m 40s\tremaining: 1m 3s\n",
            "717:\tlearn: 0.6355043\ttotal: 2m 40s\tremaining: 1m 3s\n",
            "718:\tlearn: 0.6354441\ttotal: 2m 41s\tremaining: 1m 2s\n",
            "719:\tlearn: 0.6353565\ttotal: 2m 41s\tremaining: 1m 2s\n",
            "720:\tlearn: 0.6348689\ttotal: 2m 41s\tremaining: 1m 2s\n",
            "721:\tlearn: 0.6344403\ttotal: 2m 41s\tremaining: 1m 2s\n",
            "722:\tlearn: 0.6342717\ttotal: 2m 42s\tremaining: 1m 2s\n",
            "723:\tlearn: 0.6337551\ttotal: 2m 42s\tremaining: 1m 1s\n",
            "724:\tlearn: 0.6329891\ttotal: 2m 42s\tremaining: 1m 1s\n",
            "725:\tlearn: 0.6322061\ttotal: 2m 42s\tremaining: 1m 1s\n",
            "726:\tlearn: 0.6319504\ttotal: 2m 42s\tremaining: 1m 1s\n",
            "727:\tlearn: 0.6315064\ttotal: 2m 42s\tremaining: 1m\n",
            "728:\tlearn: 0.6311368\ttotal: 2m 43s\tremaining: 1m\n",
            "729:\tlearn: 0.6304700\ttotal: 2m 43s\tremaining: 1m\n",
            "730:\tlearn: 0.6300616\ttotal: 2m 43s\tremaining: 1m\n",
            "731:\tlearn: 0.6294796\ttotal: 2m 43s\tremaining: 60s\n",
            "732:\tlearn: 0.6288645\ttotal: 2m 43s\tremaining: 59.7s\n",
            "733:\tlearn: 0.6285736\ttotal: 2m 44s\tremaining: 59.5s\n",
            "734:\tlearn: 0.6279542\ttotal: 2m 44s\tremaining: 59.3s\n",
            "735:\tlearn: 0.6274490\ttotal: 2m 44s\tremaining: 59s\n",
            "736:\tlearn: 0.6272661\ttotal: 2m 44s\tremaining: 58.8s\n",
            "737:\tlearn: 0.6269943\ttotal: 2m 44s\tremaining: 58.5s\n",
            "738:\tlearn: 0.6265346\ttotal: 2m 45s\tremaining: 58.3s\n",
            "739:\tlearn: 0.6261676\ttotal: 2m 45s\tremaining: 58.1s\n",
            "740:\tlearn: 0.6261013\ttotal: 2m 45s\tremaining: 57.8s\n",
            "741:\tlearn: 0.6255279\ttotal: 2m 45s\tremaining: 57.6s\n",
            "742:\tlearn: 0.6253890\ttotal: 2m 45s\tremaining: 57.4s\n",
            "743:\tlearn: 0.6249913\ttotal: 2m 46s\tremaining: 57.1s\n",
            "744:\tlearn: 0.6246109\ttotal: 2m 46s\tremaining: 56.9s\n",
            "745:\tlearn: 0.6244552\ttotal: 2m 46s\tremaining: 56.7s\n",
            "746:\tlearn: 0.6236521\ttotal: 2m 46s\tremaining: 56.4s\n",
            "747:\tlearn: 0.6235792\ttotal: 2m 46s\tremaining: 56.2s\n",
            "748:\tlearn: 0.6228849\ttotal: 2m 47s\tremaining: 56s\n",
            "749:\tlearn: 0.6226914\ttotal: 2m 47s\tremaining: 55.7s\n",
            "750:\tlearn: 0.6223199\ttotal: 2m 47s\tremaining: 55.5s\n",
            "751:\tlearn: 0.6218224\ttotal: 2m 47s\tremaining: 55.3s\n",
            "752:\tlearn: 0.6216262\ttotal: 2m 47s\tremaining: 55s\n",
            "753:\tlearn: 0.6215669\ttotal: 2m 48s\tremaining: 54.8s\n",
            "754:\tlearn: 0.6214670\ttotal: 2m 48s\tremaining: 54.6s\n",
            "755:\tlearn: 0.6214192\ttotal: 2m 48s\tremaining: 54.3s\n",
            "756:\tlearn: 0.6209326\ttotal: 2m 48s\tremaining: 54.1s\n",
            "757:\tlearn: 0.6202533\ttotal: 2m 48s\tremaining: 53.9s\n",
            "758:\tlearn: 0.6202019\ttotal: 2m 48s\tremaining: 53.6s\n",
            "759:\tlearn: 0.6198049\ttotal: 2m 49s\tremaining: 53.4s\n",
            "760:\tlearn: 0.6193356\ttotal: 2m 49s\tremaining: 53.2s\n",
            "761:\tlearn: 0.6192744\ttotal: 2m 49s\tremaining: 53s\n",
            "762:\tlearn: 0.6191204\ttotal: 2m 49s\tremaining: 52.7s\n",
            "763:\tlearn: 0.6186121\ttotal: 2m 49s\tremaining: 52.5s\n",
            "764:\tlearn: 0.6181739\ttotal: 2m 50s\tremaining: 52.3s\n",
            "765:\tlearn: 0.6179320\ttotal: 2m 50s\tremaining: 52s\n",
            "766:\tlearn: 0.6173591\ttotal: 2m 50s\tremaining: 51.8s\n",
            "767:\tlearn: 0.6168349\ttotal: 2m 50s\tremaining: 51.6s\n",
            "768:\tlearn: 0.6163718\ttotal: 2m 50s\tremaining: 51.3s\n",
            "769:\tlearn: 0.6160845\ttotal: 2m 51s\tremaining: 51.1s\n",
            "770:\tlearn: 0.6157919\ttotal: 2m 51s\tremaining: 50.9s\n",
            "771:\tlearn: 0.6153368\ttotal: 2m 51s\tremaining: 50.6s\n",
            "772:\tlearn: 0.6147510\ttotal: 2m 51s\tremaining: 50.5s\n",
            "773:\tlearn: 0.6144617\ttotal: 2m 52s\tremaining: 50.3s\n",
            "774:\tlearn: 0.6139309\ttotal: 2m 52s\tremaining: 50.1s\n",
            "775:\tlearn: 0.6137584\ttotal: 2m 52s\tremaining: 49.9s\n",
            "776:\tlearn: 0.6134742\ttotal: 2m 53s\tremaining: 49.7s\n",
            "777:\tlearn: 0.6129475\ttotal: 2m 53s\tremaining: 49.5s\n",
            "778:\tlearn: 0.6128241\ttotal: 2m 54s\tremaining: 49.4s\n",
            "779:\tlearn: 0.6126942\ttotal: 2m 54s\tremaining: 49.2s\n",
            "780:\tlearn: 0.6122930\ttotal: 2m 54s\tremaining: 49s\n",
            "781:\tlearn: 0.6121277\ttotal: 2m 55s\tremaining: 48.8s\n",
            "782:\tlearn: 0.6119861\ttotal: 2m 55s\tremaining: 48.6s\n",
            "783:\tlearn: 0.6112250\ttotal: 2m 55s\tremaining: 48.3s\n",
            "784:\tlearn: 0.6107620\ttotal: 2m 55s\tremaining: 48.1s\n",
            "785:\tlearn: 0.6101599\ttotal: 2m 55s\tremaining: 47.9s\n",
            "786:\tlearn: 0.6100048\ttotal: 2m 56s\tremaining: 47.6s\n",
            "787:\tlearn: 0.6098461\ttotal: 2m 56s\tremaining: 47.4s\n",
            "788:\tlearn: 0.6097055\ttotal: 2m 56s\tremaining: 47.2s\n",
            "789:\tlearn: 0.6093240\ttotal: 2m 56s\tremaining: 46.9s\n",
            "790:\tlearn: 0.6088523\ttotal: 2m 56s\tremaining: 46.7s\n",
            "791:\tlearn: 0.6087303\ttotal: 2m 56s\tremaining: 46.5s\n",
            "792:\tlearn: 0.6085834\ttotal: 2m 57s\tremaining: 46.2s\n",
            "793:\tlearn: 0.6082395\ttotal: 2m 57s\tremaining: 46s\n",
            "794:\tlearn: 0.6081825\ttotal: 2m 57s\tremaining: 45.8s\n",
            "795:\tlearn: 0.6077869\ttotal: 2m 57s\tremaining: 45.6s\n",
            "796:\tlearn: 0.6072982\ttotal: 2m 57s\tremaining: 45.3s\n",
            "797:\tlearn: 0.6068083\ttotal: 2m 58s\tremaining: 45.1s\n",
            "798:\tlearn: 0.6066675\ttotal: 2m 58s\tremaining: 44.9s\n",
            "799:\tlearn: 0.6063805\ttotal: 2m 58s\tremaining: 44.6s\n",
            "800:\tlearn: 0.6060581\ttotal: 2m 58s\tremaining: 44.4s\n",
            "801:\tlearn: 0.6058075\ttotal: 2m 58s\tremaining: 44.2s\n",
            "802:\tlearn: 0.6054826\ttotal: 2m 59s\tremaining: 43.9s\n",
            "803:\tlearn: 0.6050456\ttotal: 2m 59s\tremaining: 43.7s\n",
            "804:\tlearn: 0.6049945\ttotal: 2m 59s\tremaining: 43.5s\n",
            "805:\tlearn: 0.6047821\ttotal: 2m 59s\tremaining: 43.2s\n",
            "806:\tlearn: 0.6044350\ttotal: 2m 59s\tremaining: 43s\n",
            "807:\tlearn: 0.6038991\ttotal: 3m\tremaining: 42.8s\n",
            "808:\tlearn: 0.6034651\ttotal: 3m\tremaining: 42.5s\n",
            "809:\tlearn: 0.6033277\ttotal: 3m\tremaining: 42.3s\n",
            "810:\tlearn: 0.6030531\ttotal: 3m\tremaining: 42.1s\n",
            "811:\tlearn: 0.6027516\ttotal: 3m\tremaining: 41.9s\n",
            "812:\tlearn: 0.6026240\ttotal: 3m\tremaining: 41.6s\n",
            "813:\tlearn: 0.6022760\ttotal: 3m 1s\tremaining: 41.4s\n",
            "814:\tlearn: 0.6018891\ttotal: 3m 1s\tremaining: 41.2s\n",
            "815:\tlearn: 0.6014723\ttotal: 3m 1s\tremaining: 40.9s\n",
            "816:\tlearn: 0.6013749\ttotal: 3m 1s\tremaining: 40.7s\n",
            "817:\tlearn: 0.6012311\ttotal: 3m 1s\tremaining: 40.5s\n",
            "818:\tlearn: 0.6011858\ttotal: 3m 2s\tremaining: 40.3s\n",
            "819:\tlearn: 0.6005516\ttotal: 3m 2s\tremaining: 40s\n",
            "820:\tlearn: 0.6001461\ttotal: 3m 2s\tremaining: 39.8s\n",
            "821:\tlearn: 0.5996642\ttotal: 3m 2s\tremaining: 39.6s\n",
            "822:\tlearn: 0.5993748\ttotal: 3m 2s\tremaining: 39.3s\n",
            "823:\tlearn: 0.5989689\ttotal: 3m 3s\tremaining: 39.1s\n",
            "824:\tlearn: 0.5988484\ttotal: 3m 3s\tremaining: 38.9s\n",
            "825:\tlearn: 0.5985718\ttotal: 3m 3s\tremaining: 38.7s\n",
            "826:\tlearn: 0.5982664\ttotal: 3m 3s\tremaining: 38.4s\n",
            "827:\tlearn: 0.5981401\ttotal: 3m 3s\tremaining: 38.2s\n",
            "828:\tlearn: 0.5980097\ttotal: 3m 4s\tremaining: 38s\n",
            "829:\tlearn: 0.5976537\ttotal: 3m 4s\tremaining: 37.7s\n",
            "830:\tlearn: 0.5973771\ttotal: 3m 4s\tremaining: 37.5s\n",
            "831:\tlearn: 0.5972773\ttotal: 3m 4s\tremaining: 37.3s\n",
            "832:\tlearn: 0.5971486\ttotal: 3m 4s\tremaining: 37.1s\n",
            "833:\tlearn: 0.5968183\ttotal: 3m 5s\tremaining: 36.8s\n",
            "834:\tlearn: 0.5964003\ttotal: 3m 5s\tremaining: 36.7s\n",
            "835:\tlearn: 0.5961254\ttotal: 3m 5s\tremaining: 36.5s\n",
            "836:\tlearn: 0.5960100\ttotal: 3m 6s\tremaining: 36.3s\n",
            "837:\tlearn: 0.5959155\ttotal: 3m 6s\tremaining: 36.1s\n",
            "838:\tlearn: 0.5957826\ttotal: 3m 6s\tremaining: 35.9s\n",
            "839:\tlearn: 0.5955583\ttotal: 3m 7s\tremaining: 35.7s\n",
            "840:\tlearn: 0.5952451\ttotal: 3m 7s\tremaining: 35.5s\n",
            "841:\tlearn: 0.5951062\ttotal: 3m 8s\tremaining: 35.3s\n",
            "842:\tlearn: 0.5949388\ttotal: 3m 8s\tremaining: 35.1s\n",
            "843:\tlearn: 0.5948136\ttotal: 3m 8s\tremaining: 34.9s\n",
            "844:\tlearn: 0.5945864\ttotal: 3m 8s\tremaining: 34.6s\n",
            "845:\tlearn: 0.5942039\ttotal: 3m 9s\tremaining: 34.4s\n",
            "846:\tlearn: 0.5940811\ttotal: 3m 9s\tremaining: 34.2s\n",
            "847:\tlearn: 0.5935790\ttotal: 3m 9s\tremaining: 34s\n",
            "848:\tlearn: 0.5935165\ttotal: 3m 9s\tremaining: 33.7s\n",
            "849:\tlearn: 0.5932535\ttotal: 3m 9s\tremaining: 33.5s\n",
            "850:\tlearn: 0.5929787\ttotal: 3m 9s\tremaining: 33.3s\n",
            "851:\tlearn: 0.5929309\ttotal: 3m 10s\tremaining: 33s\n",
            "852:\tlearn: 0.5926067\ttotal: 3m 10s\tremaining: 32.8s\n",
            "853:\tlearn: 0.5924494\ttotal: 3m 10s\tremaining: 32.6s\n",
            "854:\tlearn: 0.5920962\ttotal: 3m 10s\tremaining: 32.3s\n",
            "855:\tlearn: 0.5917714\ttotal: 3m 10s\tremaining: 32.1s\n",
            "856:\tlearn: 0.5916539\ttotal: 3m 11s\tremaining: 31.9s\n",
            "857:\tlearn: 0.5912775\ttotal: 3m 11s\tremaining: 31.7s\n",
            "858:\tlearn: 0.5910056\ttotal: 3m 11s\tremaining: 31.4s\n",
            "859:\tlearn: 0.5907220\ttotal: 3m 11s\tremaining: 31.2s\n",
            "860:\tlearn: 0.5903563\ttotal: 3m 11s\tremaining: 31s\n",
            "861:\tlearn: 0.5900518\ttotal: 3m 12s\tremaining: 30.8s\n",
            "862:\tlearn: 0.5895462\ttotal: 3m 12s\tremaining: 30.5s\n",
            "863:\tlearn: 0.5893487\ttotal: 3m 12s\tremaining: 30.3s\n",
            "864:\tlearn: 0.5892610\ttotal: 3m 12s\tremaining: 30.1s\n",
            "865:\tlearn: 0.5891859\ttotal: 3m 12s\tremaining: 29.8s\n",
            "866:\tlearn: 0.5890524\ttotal: 3m 13s\tremaining: 29.6s\n",
            "867:\tlearn: 0.5888536\ttotal: 3m 13s\tremaining: 29.4s\n",
            "868:\tlearn: 0.5886588\ttotal: 3m 13s\tremaining: 29.2s\n",
            "869:\tlearn: 0.5884551\ttotal: 3m 13s\tremaining: 28.9s\n",
            "870:\tlearn: 0.5880744\ttotal: 3m 13s\tremaining: 28.7s\n",
            "871:\tlearn: 0.5878542\ttotal: 3m 14s\tremaining: 28.5s\n",
            "872:\tlearn: 0.5876520\ttotal: 3m 14s\tremaining: 28.3s\n",
            "873:\tlearn: 0.5873303\ttotal: 3m 14s\tremaining: 28s\n",
            "874:\tlearn: 0.5870437\ttotal: 3m 14s\tremaining: 27.8s\n",
            "875:\tlearn: 0.5868179\ttotal: 3m 14s\tremaining: 27.6s\n",
            "876:\tlearn: 0.5866143\ttotal: 3m 15s\tremaining: 27.4s\n",
            "877:\tlearn: 0.5865456\ttotal: 3m 15s\tremaining: 27.1s\n",
            "878:\tlearn: 0.5864741\ttotal: 3m 15s\tremaining: 26.9s\n",
            "879:\tlearn: 0.5863722\ttotal: 3m 15s\tremaining: 26.7s\n",
            "880:\tlearn: 0.5863069\ttotal: 3m 15s\tremaining: 26.4s\n",
            "881:\tlearn: 0.5861038\ttotal: 3m 15s\tremaining: 26.2s\n",
            "882:\tlearn: 0.5858673\ttotal: 3m 16s\tremaining: 26s\n",
            "883:\tlearn: 0.5858070\ttotal: 3m 16s\tremaining: 25.8s\n",
            "884:\tlearn: 0.5854410\ttotal: 3m 16s\tremaining: 25.5s\n",
            "885:\tlearn: 0.5851002\ttotal: 3m 16s\tremaining: 25.3s\n",
            "886:\tlearn: 0.5847573\ttotal: 3m 16s\tremaining: 25.1s\n",
            "887:\tlearn: 0.5846220\ttotal: 3m 17s\tremaining: 24.9s\n",
            "888:\tlearn: 0.5843205\ttotal: 3m 17s\tremaining: 24.6s\n",
            "889:\tlearn: 0.5840596\ttotal: 3m 17s\tremaining: 24.4s\n",
            "890:\tlearn: 0.5837687\ttotal: 3m 17s\tremaining: 24.2s\n",
            "891:\tlearn: 0.5834727\ttotal: 3m 17s\tremaining: 24s\n",
            "892:\tlearn: 0.5831725\ttotal: 3m 18s\tremaining: 23.7s\n",
            "893:\tlearn: 0.5831176\ttotal: 3m 18s\tremaining: 23.5s\n",
            "894:\tlearn: 0.5827950\ttotal: 3m 18s\tremaining: 23.3s\n",
            "895:\tlearn: 0.5826913\ttotal: 3m 18s\tremaining: 23.1s\n",
            "896:\tlearn: 0.5824961\ttotal: 3m 19s\tremaining: 22.9s\n",
            "897:\tlearn: 0.5824183\ttotal: 3m 19s\tremaining: 22.7s\n",
            "898:\tlearn: 0.5823694\ttotal: 3m 19s\tremaining: 22.4s\n",
            "899:\tlearn: 0.5822469\ttotal: 3m 20s\tremaining: 22.2s\n",
            "900:\tlearn: 0.5818779\ttotal: 3m 20s\tremaining: 22s\n",
            "901:\tlearn: 0.5817532\ttotal: 3m 20s\tremaining: 21.8s\n",
            "902:\tlearn: 0.5814495\ttotal: 3m 21s\tremaining: 21.6s\n",
            "903:\tlearn: 0.5813722\ttotal: 3m 21s\tremaining: 21.4s\n",
            "904:\tlearn: 0.5809985\ttotal: 3m 21s\tremaining: 21.2s\n",
            "905:\tlearn: 0.5807856\ttotal: 3m 22s\tremaining: 21s\n",
            "906:\tlearn: 0.5806903\ttotal: 3m 22s\tremaining: 20.8s\n",
            "907:\tlearn: 0.5805215\ttotal: 3m 22s\tremaining: 20.5s\n",
            "908:\tlearn: 0.5804260\ttotal: 3m 22s\tremaining: 20.3s\n",
            "909:\tlearn: 0.5803572\ttotal: 3m 23s\tremaining: 20.1s\n",
            "910:\tlearn: 0.5801295\ttotal: 3m 23s\tremaining: 19.9s\n",
            "911:\tlearn: 0.5797933\ttotal: 3m 23s\tremaining: 19.6s\n",
            "912:\tlearn: 0.5795456\ttotal: 3m 23s\tremaining: 19.4s\n",
            "913:\tlearn: 0.5793765\ttotal: 3m 23s\tremaining: 19.2s\n",
            "914:\tlearn: 0.5789824\ttotal: 3m 23s\tremaining: 18.9s\n",
            "915:\tlearn: 0.5788925\ttotal: 3m 24s\tremaining: 18.7s\n",
            "916:\tlearn: 0.5786962\ttotal: 3m 24s\tremaining: 18.5s\n",
            "917:\tlearn: 0.5785531\ttotal: 3m 24s\tremaining: 18.3s\n",
            "918:\tlearn: 0.5783328\ttotal: 3m 24s\tremaining: 18s\n",
            "919:\tlearn: 0.5780704\ttotal: 3m 24s\tremaining: 17.8s\n",
            "920:\tlearn: 0.5778212\ttotal: 3m 25s\tremaining: 17.6s\n",
            "921:\tlearn: 0.5775771\ttotal: 3m 25s\tremaining: 17.4s\n",
            "922:\tlearn: 0.5773182\ttotal: 3m 25s\tremaining: 17.1s\n",
            "923:\tlearn: 0.5772852\ttotal: 3m 25s\tremaining: 16.9s\n",
            "924:\tlearn: 0.5770243\ttotal: 3m 25s\tremaining: 16.7s\n",
            "925:\tlearn: 0.5768096\ttotal: 3m 26s\tremaining: 16.5s\n",
            "926:\tlearn: 0.5766275\ttotal: 3m 26s\tremaining: 16.2s\n",
            "927:\tlearn: 0.5764122\ttotal: 3m 26s\tremaining: 16s\n",
            "928:\tlearn: 0.5761599\ttotal: 3m 26s\tremaining: 15.8s\n",
            "929:\tlearn: 0.5759109\ttotal: 3m 26s\tremaining: 15.6s\n",
            "930:\tlearn: 0.5758179\ttotal: 3m 27s\tremaining: 15.3s\n",
            "931:\tlearn: 0.5757720\ttotal: 3m 27s\tremaining: 15.1s\n",
            "932:\tlearn: 0.5757287\ttotal: 3m 27s\tremaining: 14.9s\n",
            "933:\tlearn: 0.5756699\ttotal: 3m 27s\tremaining: 14.7s\n",
            "934:\tlearn: 0.5753611\ttotal: 3m 27s\tremaining: 14.4s\n",
            "935:\tlearn: 0.5751188\ttotal: 3m 28s\tremaining: 14.2s\n",
            "936:\tlearn: 0.5748482\ttotal: 3m 28s\tremaining: 14s\n",
            "937:\tlearn: 0.5746888\ttotal: 3m 28s\tremaining: 13.8s\n",
            "938:\tlearn: 0.5746482\ttotal: 3m 28s\tremaining: 13.6s\n",
            "939:\tlearn: 0.5744608\ttotal: 3m 28s\tremaining: 13.3s\n",
            "940:\tlearn: 0.5742761\ttotal: 3m 28s\tremaining: 13.1s\n",
            "941:\tlearn: 0.5740048\ttotal: 3m 29s\tremaining: 12.9s\n",
            "942:\tlearn: 0.5737367\ttotal: 3m 29s\tremaining: 12.7s\n",
            "943:\tlearn: 0.5736327\ttotal: 3m 29s\tremaining: 12.4s\n",
            "944:\tlearn: 0.5734557\ttotal: 3m 29s\tremaining: 12.2s\n",
            "945:\tlearn: 0.5731040\ttotal: 3m 29s\tremaining: 12s\n",
            "946:\tlearn: 0.5727236\ttotal: 3m 30s\tremaining: 11.8s\n",
            "947:\tlearn: 0.5726371\ttotal: 3m 30s\tremaining: 11.5s\n",
            "948:\tlearn: 0.5725617\ttotal: 3m 30s\tremaining: 11.3s\n",
            "949:\tlearn: 0.5724867\ttotal: 3m 30s\tremaining: 11.1s\n",
            "950:\tlearn: 0.5723621\ttotal: 3m 30s\tremaining: 10.9s\n",
            "951:\tlearn: 0.5722721\ttotal: 3m 31s\tremaining: 10.6s\n",
            "952:\tlearn: 0.5722295\ttotal: 3m 31s\tremaining: 10.4s\n",
            "953:\tlearn: 0.5721399\ttotal: 3m 31s\tremaining: 10.2s\n",
            "954:\tlearn: 0.5718819\ttotal: 3m 31s\tremaining: 9.97s\n",
            "955:\tlearn: 0.5717094\ttotal: 3m 31s\tremaining: 9.75s\n",
            "956:\tlearn: 0.5714112\ttotal: 3m 32s\tremaining: 9.53s\n",
            "957:\tlearn: 0.5711898\ttotal: 3m 32s\tremaining: 9.3s\n",
            "958:\tlearn: 0.5708778\ttotal: 3m 32s\tremaining: 9.09s\n",
            "959:\tlearn: 0.5708452\ttotal: 3m 32s\tremaining: 8.87s\n",
            "960:\tlearn: 0.5707644\ttotal: 3m 33s\tremaining: 8.66s\n",
            "961:\tlearn: 0.5705472\ttotal: 3m 33s\tremaining: 8.44s\n",
            "962:\tlearn: 0.5705123\ttotal: 3m 34s\tremaining: 8.22s\n",
            "963:\tlearn: 0.5702635\ttotal: 3m 34s\tremaining: 8.01s\n",
            "964:\tlearn: 0.5702195\ttotal: 3m 34s\tremaining: 7.79s\n",
            "965:\tlearn: 0.5701673\ttotal: 3m 35s\tremaining: 7.57s\n",
            "966:\tlearn: 0.5700725\ttotal: 3m 35s\tremaining: 7.36s\n",
            "967:\tlearn: 0.5699182\ttotal: 3m 35s\tremaining: 7.13s\n",
            "968:\tlearn: 0.5698750\ttotal: 3m 35s\tremaining: 6.91s\n",
            "969:\tlearn: 0.5697989\ttotal: 3m 36s\tremaining: 6.68s\n",
            "970:\tlearn: 0.5696049\ttotal: 3m 36s\tremaining: 6.46s\n",
            "971:\tlearn: 0.5695429\ttotal: 3m 36s\tremaining: 6.24s\n",
            "972:\tlearn: 0.5694133\ttotal: 3m 36s\tremaining: 6.01s\n",
            "973:\tlearn: 0.5693178\ttotal: 3m 36s\tremaining: 5.79s\n",
            "974:\tlearn: 0.5690718\ttotal: 3m 37s\tremaining: 5.57s\n",
            "975:\tlearn: 0.5687630\ttotal: 3m 37s\tremaining: 5.34s\n",
            "976:\tlearn: 0.5687389\ttotal: 3m 37s\tremaining: 5.12s\n",
            "977:\tlearn: 0.5685965\ttotal: 3m 37s\tremaining: 4.9s\n",
            "978:\tlearn: 0.5684665\ttotal: 3m 37s\tremaining: 4.67s\n",
            "979:\tlearn: 0.5681690\ttotal: 3m 38s\tremaining: 4.45s\n",
            "980:\tlearn: 0.5679783\ttotal: 3m 38s\tremaining: 4.23s\n",
            "981:\tlearn: 0.5678858\ttotal: 3m 38s\tremaining: 4s\n",
            "982:\tlearn: 0.5678386\ttotal: 3m 38s\tremaining: 3.78s\n",
            "983:\tlearn: 0.5675627\ttotal: 3m 38s\tremaining: 3.56s\n",
            "984:\tlearn: 0.5675338\ttotal: 3m 39s\tremaining: 3.33s\n",
            "985:\tlearn: 0.5675109\ttotal: 3m 39s\tremaining: 3.11s\n",
            "986:\tlearn: 0.5673591\ttotal: 3m 39s\tremaining: 2.89s\n",
            "987:\tlearn: 0.5671181\ttotal: 3m 39s\tremaining: 2.67s\n",
            "988:\tlearn: 0.5669598\ttotal: 3m 39s\tremaining: 2.44s\n",
            "989:\tlearn: 0.5669162\ttotal: 3m 39s\tremaining: 2.22s\n",
            "990:\tlearn: 0.5666223\ttotal: 3m 40s\tremaining: 2s\n",
            "991:\tlearn: 0.5665161\ttotal: 3m 40s\tremaining: 1.78s\n",
            "992:\tlearn: 0.5664860\ttotal: 3m 40s\tremaining: 1.55s\n",
            "993:\tlearn: 0.5664467\ttotal: 3m 40s\tremaining: 1.33s\n",
            "994:\tlearn: 0.5662484\ttotal: 3m 40s\tremaining: 1.11s\n",
            "995:\tlearn: 0.5662211\ttotal: 3m 41s\tremaining: 888ms\n",
            "996:\tlearn: 0.5661605\ttotal: 3m 41s\tremaining: 666ms\n",
            "997:\tlearn: 0.5657793\ttotal: 3m 41s\tremaining: 444ms\n",
            "998:\tlearn: 0.5655218\ttotal: 3m 41s\tremaining: 222ms\n",
            "999:\tlearn: 0.5654143\ttotal: 3m 41s\tremaining: 0us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate evaluation metrics for Random Forest Regressor\n",
        "mape_train_rf = mean_absolute_percentage_error(y_train, y_train_pred_rf)\n",
        "mape_test_rf = mean_absolute_percentage_error(y_test, y_test_pred_rf)\n",
        "r2_train_rf = r2_score(y_train, y_train_pred_rf)\n",
        "r2_test_rf = r2_score(y_test, y_test_pred_rf)\n",
        "rmse_train_rf = mean_squared_error(y_train, y_train_pred_rf, squared=False)\n",
        "rmse_test_rf = mean_squared_error(y_test, y_test_pred_rf, squared=False)\n",
        "mae_train_rf = mean_absolute_error(y_train, y_train_pred_rf)\n",
        "mae_test_rf = mean_absolute_error(y_test, y_test_pred_rf)\n",
        "\n",
        "# Calculate evaluation metrics for CatBoost Regressor\n",
        "mape_train_catboost = mean_absolute_percentage_error(y_train, y_train_pred_catboost)\n",
        "mape_test_catboost = mean_absolute_percentage_error(y_test, y_test_pred_catboost)\n",
        "r2_train_catboost = r2_score(y_train, y_train_pred_catboost)\n",
        "r2_test_catboost = r2_score(y_test, y_test_pred_catboost)\n",
        "rmse_train_catboost = mean_squared_error(y_train, y_train_pred_catboost, squared=False)\n",
        "rmse_test_catboost = mean_squared_error(y_test, y_test_pred_catboost, squared=False)\n",
        "mae_train_catboost = mean_absolute_error(y_train, y_train_pred_catboost)\n",
        "mae_test_catboost = mean_absolute_error(y_test, y_test_pred_catboost)\n",
        "\n",
        "# Calculate evaluation metrics for XGBoost Regressor\n",
        "mape_train_xgb = mean_absolute_percentage_error(y_train, y_train_pred_xgb)\n",
        "mape_test_xgb = mean_absolute_percentage_error(y_test, y_test_pred_xgb)\n",
        "r2_train_xgb = r2_score(y_train, y_train_pred_xgb)\n",
        "r2_test_xgb = r2_score(y_test, y_test_pred_xgb)\n",
        "rmse_train_xgb = mean_squared_error(y_train, y_train_pred_xgb, squared=False)\n",
        "rmse_test_xgb = mean_squared_error(y_test, y_test_pred_xgb, squared=False)\n",
        "mae_train_xgb = mean_absolute_error(y_train, y_train_pred_xgb)\n",
        "mae_test_xgb = mean_absolute_error(y_test, y_test_pred_xgb)\n",
        "\n",
        "# Calculate evaluation metrics for Gradient Boosting Regressor\n",
        "mape_train_gra = mean_absolute_percentage_error(y_train, y_train_pred_gra)\n",
        "mape_test_gra = mean_absolute_percentage_error(y_test, y_test_pred_gra)\n",
        "r2_train_gra = r2_score(y_train, y_train_pred_gra)\n",
        "r2_test_gra = r2_score(y_test, y_test_pred_gra)\n",
        "rmse_train_gra = mean_squared_error(y_train, y_train_pred_gra, squared=False)\n",
        "rmse_test_gra = mean_squared_error(y_test, y_test_pred_gra, squared=False)\n",
        "mae_train_gra = mean_absolute_error(y_train, y_train_pred_gra)\n",
        "mae_test_gra = mean_absolute_error(y_test, y_test_pred_gra)\n",
        "\n",
        "# Calculate evaluation metrics for ExtraTreesRegressor\n",
        "mape_train_et = mean_absolute_percentage_error(y_train, y_train_pred_et)\n",
        "mape_test_et = mean_absolute_percentage_error(y_test, y_test_pred_et)\n",
        "r2_train_et = r2_score(y_train, y_train_pred_et)\n",
        "r2_test_et = r2_score(y_test, y_test_pred_et)\n",
        "rmse_train_et = mean_squared_error(y_train, y_train_pred_et, squared=False)\n",
        "rmse_test_et = mean_squared_error(y_test, y_test_pred_et, squared=False)\n",
        "mae_train_et = mean_absolute_error(y_train, y_train_pred_et)\n",
        "mae_test_et = mean_absolute_error(y_test, y_test_pred_et)\n"
      ],
      "metadata": {
        "id": "wsBivCmPLt9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the evaluation metrics for Random Forest Regressor\n",
        "print(\"Random Forest Regressor:\")\n",
        "print(\"Train RMSE:\", rmse_train_rf)\n",
        "print(\"Test RMSE:\", rmse_test_rf)\n",
        "print(\"Train MAE:\", mae_train_rf)\n",
        "print(\"Test MAE:\", mae_test_rf)\n",
        "print(\"Train MAPE:\", mape_train_rf)\n",
        "print(\"Test MAPE:\", mape_test_rf)\n",
        "print(\"Train R^2:\", r2_train_rf)\n",
        "print(\"Test R^2:\", r2_test_rf)\n",
        "\n",
        "# Print the evaluation metrics for CatBoost Regressor\n",
        "print(\"CatBoost Regressor:\")\n",
        "print(\"Train RMSE:\", rmse_train_catboost)\n",
        "print(\"Test RMSE:\", rmse_test_catboost)\n",
        "print(\"Train MAE:\", mae_train_catboost)\n",
        "print(\"Test MAE:\", mae_test_catboost)\n",
        "print(\"Train MAPE:\", mape_train_catboost)\n",
        "print(\"Test MAPE:\", mape_test_catboost)\n",
        "print(\"Train R^2:\", r2_train_catboost)\n",
        "print(\"Test R^2:\", r2_test_catboost)\n",
        "\n",
        "# Print the evaluation metrics for XGBoost Regressor\n",
        "print(\"XGBoost Regressor:\")\n",
        "print(\"Train RMSE:\", rmse_train_xgb)\n",
        "print(\"Test RMSE:\", rmse_test_xgb)\n",
        "print(\"Train MAE:\", mae_train_xgb)\n",
        "print(\"Test MAE:\", mae_test_xgb)\n",
        "print(\"Train MAPE:\", mape_train_xgb)\n",
        "print(\"Test MAPE:\", mape_test_xgb)\n",
        "print(\"Train R^2:\", r2_train_xgb)\n",
        "print(\"Test R^2:\", r2_test_xgb)\n",
        "\n",
        "# Print the evaluation metrics for Gradient Boosting Regressor\n",
        "print(\"Gradient Boosting Regressor:\")\n",
        "print(\"Train RMSE:\", rmse_train_gra)\n",
        "print(\"Test RMSE:\", rmse_test_gra)\n",
        "print(\"Train MAE:\", mae_train_gra)\n",
        "print(\"Test MAE:\", mae_test_gra)\n",
        "print(\"Train MAPE:\", mape_train_gra)\n",
        "print(\"Test MAPE:\", mape_test_gra)\n",
        "print(\"Train R^2:\", r2_train_gra)\n",
        "print(\"Test R^2:\", r2_test_gra)\n",
        "\n",
        "# Print the evaluation metrics for ExtraTreesRegressor\n",
        "print(\"ExtraTreesRegressor:\")\n",
        "print(\"Train RMSE:\", rmse_train_et)\n",
        "print(\"Test RMSE:\", rmse_test_et)\n",
        "print(\"Train MAE:\", mae_train_et)\n",
        "print(\"Test MAE:\", mae_test_et)\n",
        "print(\"Train MAPE:\", mape_train_et)\n",
        "print(\"Test MAPE:\", mape_test_et)\n",
        "print(\"Train R^2:\", r2_train_et)\n",
        "print(\"Test R^2:\", r2_test_et)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUEcn_29L0Ub",
        "outputId": "6c38eb45-4bfd-4bd6-9a4c-4a8bd176beb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor:\n",
            "Train RMSE: 0.8374304594379701\n",
            "Test RMSE: 1.9061985032996662\n",
            "Train MAE: 0.5580601102070508\n",
            "Test MAE: 1.4180283241449791\n",
            "Train MAPE: 32855442121386.336\n",
            "Test MAPE: 248345101013331.9\n",
            "Train R^2: 0.8551674791061156\n",
            "Test R^2: 0.3149960045158233\n",
            "CatBoost Regressor:\n",
            "Train RMSE: 0.5654142536136214\n",
            "Test RMSE: 1.8544947589027168\n",
            "Train MAE: 0.2645235303948474\n",
            "Test MAE: 1.3989908672800966\n",
            "Train MAPE: 1881030442500.7712\n",
            "Test MAPE: 198388633187903.3\n",
            "Train R^2: 0.9339759610312499\n",
            "Test R^2: 0.35165214735351347\n",
            "XGBoost Regressor:\n",
            "Train RMSE: 0.5535738731566742\n",
            "Test RMSE: 1.8919196539096232\n",
            "Train MAE: 0.19780915230290186\n",
            "Test MAE: 1.415141092654428\n",
            "Train MAPE: 15296979052016.682\n",
            "Test MAPE: 185488687965413.4\n",
            "Train R^2: 0.9367122358847497\n",
            "Test R^2: 0.32521995035718676\n",
            "Gradient Boosting Regressor:\n",
            "Train RMSE: 0.9094385494306155\n",
            "Test RMSE: 1.9040652086431076\n",
            "Train MAE: 0.6789543219840515\n",
            "Test MAE: 1.459500429968728\n",
            "Train MAPE: 12978525246082.219\n",
            "Test MAPE: 194110411017023.0\n",
            "Train R^2: 0.8291892097780373\n",
            "Test R^2: 0.3165283713241249\n",
            "ExtraTreesRegressor:\n",
            "Train RMSE: 0.524207944338919\n",
            "Test RMSE: 1.8826445149306168\n",
            "Train MAE: 0.09557033152275711\n",
            "Test MAE: 1.3925594736842104\n",
            "Train MAPE: 0.03260219052970502\n",
            "Test MAPE: 233646748667981.66\n",
            "Train R^2: 0.943248704463501\n",
            "Test R^2: 0.3318199527798863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3IxivxrL1qd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}